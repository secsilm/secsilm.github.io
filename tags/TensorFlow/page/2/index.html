
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Alan Lee">
    <title>标签: TensorFlow - Alan Lee</title>
    <meta name="author" content="Alan Lee">
    
        <meta name="keywords" content="hexo,python,tensorflow,pytorch,nlp,natural language processing,deep learning,machine learning,large language models,llms,">
    
    
        <link rel="icon" href="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png">
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="Machine Learning, Deep Learning, NLP">
<meta property="og:type" content="blog">
<meta property="og:title" content="Alan Lee">
<meta property="og:url" content="https://alanlee.fun/tags/TensorFlow/page/2/index.html">
<meta property="og:site_name" content="Alan Lee">
<meta property="og:description" content="Machine Learning, Deep Learning, NLP">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Alan Lee">
<meta property="article:tag" content="hexo">
<meta property="article:tag" content="python">
<meta property="article:tag" content="tensorflow">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="nlp">
<meta property="article:tag" content="natural language processing">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="large language models">
<meta property="article:tag" content="llms">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@bluekirin93">
    
    
        
    
    
        <meta property="og:image" content="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-7psn7jtnqx8dcatt1chsgye58vhpeeqkf8gzcb5iijzope7gwcvezy8gigh2.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111553531-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111553531-1');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
    <style>
        ::-moz-selection { /* Code for Firefox */
          background: #FFBFBF;
        }
        
        ::selection {
          background: #FFBFBF;
        }
    </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Alan Lee
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Alan Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/secsilm"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/bluekirin93"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:secsilm@outlook.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2017/02/16/tensorflow-1.0/"
                            aria-label=": TensorFlow 1.0 发布"
                        >
                            TensorFlow 1.0 发布
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-02-16T10:46:55+08:00">
	
		    2017 年 2 月 16 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>前面写了 <a href="https://secsilm.github.io/2016/12/01/installing-tensorflow/">TensorFlow 在Windows上的安装教程</a>，当时版本还是 0.12 。</p>
<p>NOW</p>
<p>首届 <a href="https://events.withgoogle.com/tensorflow-dev-summit/watch-the-videos/#content">TensorFlow 开发者大会</a>（TensorFlow Dev Summit）已于美国时间昨日召开，YouTube 还进行了直播。更重要的是，<strong>TensorFlow 1.0</strong> 版本发布。Google Research Blog 也于昨天在 <a href="https://research.googleblog.com/2017/02/announcing-tensorflow-10.html">博客</a> 中公布了这一消息。</p>
                    
                        <a
                            href="/2017/02/16/tensorflow-1.0/"
                            class="postShorten-excerpt_link link"
                            aria-label=": TensorFlow 1.0 发布"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/12/28/tensorflow-cnn-no-tensorboard/"
                            aria-label=": TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版"
                        >
                            TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-12-28T12:13:13+08:00">
	
		    2016 年 12 月 28 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p><a href="http://blog.csdn.net/u010099080/article/details/53234227">前面</a> 有篇博文讲了多层感知器，也就是一般的前馈神经网络，文章里使用 CIFAR10 数据集得到的测试准确率是 <strong>46.98%</strong>。今天我们使用更适合处理图像的卷积神经网络来处理相同的数据集 - CIFAR10，来看下准确率能达到多少。</p>
<p>本文代码基于 <a href="https://www.tensorflow.org/tutorials/deep_cnn/">TensorFlow 的官方文档</a> 做了些许修改，完整代码及结果图片可从 <a href="http://download.csdn.net/download/u010099080/9723302">这里</a> 下载。</p>
<p><a href="http://blog.csdn.net/u010099080/article/details/62882006">这篇</a> 文章是对本文的一个升级，增加了 TensorBoard 的实现，可以在浏览器中查看可视化结果，包括准确率、损失、计算图、训练时间和内存信息等。</p>
                    
                        <a
                            href="/2016/12/28/tensorflow-cnn-no-tensorboard/"
                            class="postShorten-excerpt_link link"
                            aria-label=": TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/12/10/tensorboard-mnist-pca/"
                            aria-label=": 在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集"
                        >
                            在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-12-10T07:23:02+08:00">
	
		    2016 年 12 月 10 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <!-- toc -->
<p>主成分分析（PCA）是一种常用的数据降维方法，可以将高维数据在二维或者三维可视化呈现。具体原理我在这里就不再详述，网上有很多教程都不错，可以参考 <a href="https://my.oschina.net/gujianhan/blog/225241">这里</a> 或者 <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA 的维基百科页面</a>。</p>
                    
                        <a
                            href="/2016/12/10/tensorboard-mnist-pca/"
                            class="postShorten-excerpt_link link"
                            aria-label=": 在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/12/01/installing-tensorflow/"
                            aria-label=": Windows10 64 位下安装 TensorFlow - 官方原生支持"
                        >
                            Windows10 64 位下安装 TensorFlow - 官方原生支持
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-12-01T09:11:00+08:00">
	
		    2016 年 12 月 1 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p><a href="http://localhost:4000/2016/08/27/ubuntu-installing-tensorflow/">之前</a> 写过一篇在 ubuntu 下安装 TensorFlow 的教程，那个时候 TensorFlow 官方还不支持 Windows 系统，虽然可以通过其他方法安装，但是终究不是原生的，而且安装过程繁琐易错。好消息是，Google官方在11月29号的开发者博客中宣布新的版本（0.12）将 <a href="https://developers.googleblog.com/2016/11/tensorflow-0-12-adds-support-for-windows.html">增加对Windows的支持</a>，我11月30号知道的，立马就安装试了试，安装过程非常简单，不过也有一些需要手动调整。</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://i.imgur.com/0lbB25k.png" title="这里写图片描述" data-caption="这里写图片描述" data-fancybox="default"><img class="fig-img" src="https://i.imgur.com/0lbB25k.png" alt="这里写图片描述"></a><span class="caption">这里写图片描述</span></div>
<hr>
<h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>这里我会列出对本文的更新。</p>
<ul>
<li>2017 年 3 月 1 日：cuDNN 版本从 5.0 升级到 5.1 版本，更新 cuda 和 cudnn 下载地址。</li>
<li>2017 年 3 月 20 日：标记 <em>安装前准备</em> 中的第五条 <em>确保你安装了 VS2015 或者 2013 或者 2010。</em> 为存疑。这是我之前在 TensorFlow 官网看到的，但是现在去翻了翻找不到了。如果有同学没有安装 VS 就把 TensorFlow 安装成功了的话，请在下方评论区说明下，到时候我会将这个要求标记为删除。谢谢。</li>
<li>2017 年 3 月 26 日：更新 TensorFlow 安装命令。</li>
<li>2017 年 4 月 18 日：<ul>
<li><em>安装前准备</em>  第五条标记为删除，经过我再次试验发现不需要 VS 的支持。</li>
<li>增加问题 <code>Cannot remove entries from nonexistent file</code> 的解决办法。</li>
</ul>
</li>
<li>2017 年 7 月 20 日：增加问题 <code>ImportError: DLL load failed: 找不到指定的模块。</code> 、<code>ImportError: No module named &#39;_pywrap_tensorflow_internal&#39;</code> 和 <code>ImportError: No module named &#39;tensorflow.python.pywrap_tensorflow_internal</code> 的时候` 的解决办法。</li>
<li>2017 年 7 月 31日：更新关于 Python 版本的说明，TensorFlow 从 1.2 开始在 Windows 上支持 Python 3.6。感谢评论区 @Vince_Ace 提供的信息。</li>
<li>2017 年 8 月 20 日：TensorFlow 1.3 发布，更新 cuDNN 版本说明。感谢评论区 @myseth1023 提供的信息。</li>
<li>2017 年 8 月 21 日：删除 <em>安装cuDNN</em> 中容易误导人的部分（关于添加环境变量）。</li>
<li>2018 年 3 月 12 日：TensorFlow 1.6 发布，更新相关说明，详细发布说明参考 <a href="https://github.com/tensorflow/tensorflow/releases/tag/v1.6.0">Release TensorFlow 1.6.0</a>。</li>
<li>2018 年 3 月 18 日：增加问题 #4 及其解决办法。</li>
<li>2019 年 4 月 5 日：增加问题 #5 及其解决办法（针对 TensorFlow 1.13）。</li>
</ul>
<hr>
<h2 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h2><p>TensorFlow 有两个版本：<strong>CPU</strong> 版本和 <strong>GPU</strong> 版本。GPU 版本需要 <strong>CUDA</strong> 和 <strong>cuDNN</strong> 的支持，CPU 版本不需要。如果你要安装 GPU 版本，<strong>请先确认你的显卡支持 CUDA</strong>。我安装的是 GPU 版本，采用 <strong>pip 安装方式</strong>，所以就以 GPU 安装为例，CPU 版本只不过不需要安装 CUDA 和 cuDNN。</p>
<ol>
<li>在 <a href="https://developer.nvidia.com/cuda-gpus">这里</a> 确认你的显卡支持 CUDA。</li>
<li>确保你的 Python 版本是 <strong>3.5</strong> 64 位及以上。（TensorFlow 从 1.2 开始支持 Python 3.6，之前的<strong>官方</strong>是不支持的）</li>
<li>确保你有稳定的网络连接。</li>
<li>确保你的 pip 版本 &gt;= 8.1。用 <code>pip -V</code> 查看当前 <code>pip</code> 版本，用 <code>python -m pip install -U pip</code> 升级<code>pip</code> 。</li>
<li><del>确保你安装了 VS2015 或者 2013 或者 2010。此条非必须，删除。</del></li>
</ol>
<p>此外，建议安装 Anaconda，因为这个集成了很多科学计算所必需的库，能够避免很多依赖问题，安装教程可以参考 <a href="http://blog.csdn.net/u010099080/article/details/52333935">这里</a>。</p>
<p>以上条件符合，那么恭喜你可以开始下载 CUDA 和 cuDNN 的安装包了，注意版本号会由于 TensorFlow 不同版本有变化，此处请结合下面的<a href="http://blog.csdn.net/u010099080/article/details/53418159#%E5%AE%89%E8%A3%85-cuda">安装 CUDA</a> 和<a href="http://blog.csdn.net/u010099080/article/details/53418159#%E5%AE%89%E8%A3%85-cudnn">安装 cuDNN</a> 说明）。</p>
<hr>
<h2 id="安装-TensorFlow"><a href="#安装-TensorFlow" class="headerlink" title="安装 TensorFlow"></a>安装 TensorFlow</h2><p>由于 Google 那帮人已经把 TensorFlow 打成了一个 pip 安装包，所以现在可以用正常安装包的方式安装 TensorFlow 了，就是进入命令行执行下面这一条简单的语句：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># GPU版本</span><br><span class="line">pip3 install --upgrade tensorflow-gpu</span><br><span class="line"></span><br><span class="line"># CPU版本</span><br><span class="line">pip3 install --upgrade tensorflow</span><br></pre></td></tr></table></figure></p>
<p>然后就开始安装了，速度视网速而定。</p>
<p>安装网之后你试着在 Python 中<code>import tensorflow</code>会告诉你没有找到 CUDA 和 cuDNN，所以下一步就是安装这两个东西。</p>
<hr>
<h2 id="安装-CUDA"><a href="#安装-CUDA" class="headerlink" title="安装 CUDA"></a>安装 CUDA</h2><blockquote>
<ul>
<li>TensorFlow 1.6：CUDA 9.0</li>
<li>TensorFlow 1.13.1：CUDA 10.0</li>
</ul>
</blockquote>
<p>这个也是很简单的，<strong>首先根据上面的版本去<a href="https://developer.nvidia.com/cuda-toolkit-archive">官网</a>下载对应的安装包（~ 1.4 GB）</strong>。下载完那个 exe 文件就是 CUDA 的安装程序，直接双击执行就可以了，就像安装正常的其他软件一样，安装过程屏幕可能会闪烁，不要紧，而且安装时间有点长。</p>
<p>安装完之后系统变量会自动为你添加上，这个不用管。</p>
<p>测试一下是否安装成功，命令行输入 <code>nvcc -V</code> ，看到版本信息就表示安装成功了。</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://i.imgur.com/Qjk8FSf.png" title="nvcc" data-caption="nvcc" data-fancybox="default"><img class="fig-img" src="https://i.imgur.com/Qjk8FSf.png" alt="nvcc"></a><span class="caption">nvcc</span></div>
<hr>
<!-- toc -->
<h2 id="安装-cuDNN"><a href="#安装-cuDNN" class="headerlink" title="安装 cuDNN"></a>安装 cuDNN</h2>
                    
                        <a
                            href="/2016/12/01/installing-tensorflow/"
                            class="postShorten-excerpt_link link"
                            aria-label=": Windows10 64 位下安装 TensorFlow - 官方原生支持"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/11/19/tensorflow-mlp/"
                            aria-label=": TensorFlow 中的多层感知器（MLP）"
                        >
                            TensorFlow 中的多层感知器（MLP）
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-11-19T08:56:14+08:00">
	
		    2016 年 11 月 19 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>前面有几篇博文讲了使用 <code>TensorFlow</code> 实现<a href="http://blog.csdn.net/u010099080/article/details/52894773">线性回归</a>和<a href="http://blog.csdn.net/u010099080/article/details/53054519">逻辑斯蒂回归</a>，这次来说下多层感知器（Multi-Layer Perceptron）的 <code>TensorFlow</code> 实现。</p>
<p><strong>本篇博文的代码及结果图片等可以在<a href="http://download.csdn.net/download/u010099080/9687585">这里</a>下载，里面包含TensorFlow的实现和sklearn的实现，以及各自的结果图片。</strong></p>
                    
                        <a
                            href="/2016/11/19/tensorflow-mlp/"
                            class="postShorten-excerpt_link link"
                            aria-label=": TensorFlow 中的多层感知器（MLP）"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/11/06/tensorflow-logistic-regression/"
                            aria-label=": TensorFlow 中的 Logistic Regression"
                        >
                            TensorFlow 中的 Logistic Regression
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-11-06T03:13:49+08:00">
	
		    2016 年 11 月 6 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>前面提到了<a href="http://blog.csdn.net/u010099080/article/details/52894773">使用 <code>TensorFlow</code> 进行线性回归</a>以及<a href="http://blog.csdn.net/u010099080/article/details/52965337">学习率、迭代次数和初始化方式对准确率的影响</a>，这次来谈一下如何使用 <code>TensorFlow</code> 进行 Logistics Regression（以下简称 LR）。关于LR的理论内容我就不再赘述了，网上有很多资料讲，这里我就写下 LR 所用的损失函数：</p>
<script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))\right]</script><p>其实整个程序下来和线性回归差不多，只不过是损失函数的定义不一样了，当然数据也不一样了，一个是用于回归的，一个是用于分类的。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集不再是经典的<code>MNIST</code>数据集，而是我在UCI上找的用于二分类的数据集，因为我觉得老用经典的数据集不能很好的<strong>理解</strong>整个程序。数据集可以从<a href="http://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+">这里</a>下载，数据集是关于房屋居住的，给出一些影响房屋居住的因素和是否居住（二分类），例如光照、温度等。数据集有3个txt文件，本篇使用的是<code>datatraining.txt</code>,数据量是8143×7，删除日期数据，然后按照<code>75:25</code>的比例拆分成训练集和测试集，然后做一些必要的<code>reshape</code>。</p>
<p>数据集大致是这样子的：<br><img src="http://i.imgur.com/doWttAU.png" alt=""></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, division</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;datatraining.txt&quot;</span>)</span><br><span class="line"><span class="comment"># 拆分数据</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data[[<span class="string">&quot;Temperature&quot;</span>, <span class="string">&quot;Humidity&quot;</span>, <span class="string">&quot;Light&quot;</span>, <span class="string">&quot;CO2&quot;</span>, <span class="string">&quot;HumidityRatio&quot;</span>]].values, data[<span class="string">&quot;Occupancy&quot;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>), random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># one-hot 编码</span></span><br><span class="line">y_train = tf.concat(<span class="number">1</span>, [<span class="number">1</span> - y_train, y_train])</span><br><span class="line">y_test = tf.concat(<span class="number">1</span>, [<span class="number">1</span> - y_test, y_test])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置模型</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">training_epochs = <span class="number">50</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">n_samples = X_train.shape[<span class="number">0</span>]</span><br><span class="line">n_features = <span class="number">5</span></span><br><span class="line">n_class = <span class="number">2</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_features])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, n_class])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型参数</span></span><br><span class="line">W = tf.Variable(tf.zeros([n_features, n_class]))</span><br><span class="line">b = tf.Variable(tf.zeros([n_class]))</span><br><span class="line"><span class="comment"># W = tf.Variable(tf.truncated_normal([n_features, n_class-1]))</span></span><br><span class="line"><span class="comment"># b = tf.Variable(tf.truncated_normal([n_class]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型，此处使用与线性回归一样的定义</span></span><br><span class="line"><span class="comment"># 因为在后面定义损失的时候会加上映射</span></span><br><span class="line">pred = tf.matmul(x, W) + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))</span><br><span class="line"><span class="comment"># cost = tf.nn.sigmoid_cross_entropy_with_logits(pred, y)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化所有变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0</span></span><br><span class="line">        total_batch = <span class="built_in">int</span>(n_samples / batch_size)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(total_batch):</span><br><span class="line">            _, c = sess.run([optimizer, cost], </span><br><span class="line">                            feed_dict=&#123;x: X_train[i * batch_size : (i+<span class="number">1</span>) * batch_size], </span><br><span class="line">                                      y: y_train[i * batch_size : (i+<span class="number">1</span>) * batch_size, :].<span class="built_in">eval</span>()&#125;)</span><br><span class="line">            avg_cost = c / total_batch</span><br><span class="line">        plt.plot(epoch+<span class="number">1</span>, avg_cost, <span class="string">&#x27;co&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (epoch+<span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>, <span class="string">&quot;%04d&quot;</span> % (epoch+<span class="number">1</span>), <span class="string">&quot;cost=&quot;</span>, avg_cost)</span><br><span class="line">            </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Optimization Finished!&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Testing Accuracy:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;x: X_train, y:y_train.<span class="built_in">eval</span>()&#125;))</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Epoch&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Cost&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 0.402052676091</span><br><span class="line">Epoch: 0002 cost= 0.384176723293</span><br><span class="line">Epoch: 0003 cost= 0.174337043137</span><br><span class="line">Epoch: 0004 cost= 0.131257948328</span><br><span class="line">Epoch: 0005 cost= 0.116865955415</span><br><span class="line">Epoch: 0006 cost= 0.167843505984</span><br><span class="line">Epoch: 0007 cost= 0.0734717650492</span><br><span class="line">Epoch: 0008 cost= 0.134278797712</span><br><span class="line">Epoch: 0009 cost= 0.107930605529</span><br><span class="line">Epoch: 0010 cost= 0.0559994509963</span><br><span class="line">Epoch: 0011 cost= 0.0894105786183</span><br><span class="line">Epoch: 0012 cost= 0.112936254408</span><br><span class="line">Epoch: 0013 cost= 0.0598722950357</span><br><span class="line">Epoch: 0014 cost= 0.0590479530272</span><br><span class="line">Epoch: 0015 cost= 0.085669126667</span><br><span class="line">Epoch: 0016 cost= 0.0516053653154</span><br><span class="line">Epoch: 0017 cost= 0.0587136237348</span><br><span class="line">Epoch: 0018 cost= 0.0668616529371</span><br><span class="line">Epoch: 0019 cost= 0.0612989566365</span><br><span class="line">Epoch: 0020 cost= 0.0527745035828</span><br><span class="line">Epoch: 0021 cost= 0.0758241278226</span><br><span class="line">Epoch: 0022 cost= 0.0845051749808</span><br><span class="line">Epoch: 0023 cost= 0.0364650820122</span><br><span class="line">Epoch: 0024 cost= 0.0526885400053</span><br><span class="line">Epoch: 0025 cost= 0.0451166786131</span><br><span class="line">Epoch: 0026 cost= 0.0508907896573</span><br><span class="line">Epoch: 0027 cost= 0.0619052668087</span><br><span class="line">Epoch: 0028 cost= 0.0560943103227</span><br><span class="line">Epoch: 0029 cost= 0.0425660180264</span><br><span class="line">Epoch: 0030 cost= 0.0601769588033</span><br><span class="line">Epoch: 0031 cost= 0.0461903712789</span><br><span class="line">Epoch: 0032 cost= 0.0437817573547</span><br><span class="line">Epoch: 0033 cost= 0.102960703803</span><br><span class="line">Epoch: 0034 cost= 0.0599972771817</span><br><span class="line">Epoch: 0035 cost= 0.10071516037</span><br><span class="line">Epoch: 0036 cost= 0.101918243971</span><br><span class="line">Epoch: 0037 cost= 0.102948681253</span><br><span class="line">Epoch: 0038 cost= 0.0239826597151</span><br><span class="line">Epoch: 0039 cost= 0.02541697807</span><br><span class="line">Epoch: 0040 cost= 0.039644296052</span><br><span class="line">Epoch: 0041 cost= 0.0564842145951</span><br><span class="line">Epoch: 0042 cost= 0.0651661059895</span><br><span class="line">Epoch: 0043 cost= 0.0559316267733</span><br><span class="line">Epoch: 0044 cost= 0.058336042967</span><br><span class="line">Epoch: 0045 cost= 0.0420891652342</span><br><span class="line">Epoch: 0046 cost= 0.0113296391534</span><br><span class="line">Epoch: 0047 cost= 0.0151269641079</span><br><span class="line">Epoch: 0048 cost= 0.070616901898</span><br><span class="line">Epoch: 0049 cost= 0.0543320648006</span><br><span class="line">Epoch: 0050 cost= 0.0490373939764</span><br><span class="line">Optimization Finished!</span><br><span class="line">Testing Accuracy: 0.973473</span><br></pre></td></tr></table></figure>
<p><img src="http://i.imgur.com/Ri1jJQq.png" alt=""></p>
<p>可以看到最终准确率达到了97%，这里注意标签要进行<code>one-hot</code>编码。</p>
<h2 id="与sklearn的比较"><a href="#与sklearn的比较" class="headerlink" title="与sklearn的比较"></a>与sklearn的比较</h2><p>我用相同的数据集使用<code>sklearn</code>实现了LR,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clf = LogisticRegression()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">clf.score(X_test, y_test)</span><br></pre></td></tr></table></figure>
<p>结果准确率是0.98624754420432215，而且训练时间大为缩短。</p>
<hr>
<!-- toc -->
<h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2>
                    
                        <a
                            href="/2016/11/06/tensorflow-logistic-regression/"
                            class="postShorten-excerpt_link link"
                            aria-label=": TensorFlow 中的 Logistic Regression"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/10/29/tensorflow-hyperparams/"
                            aria-label=": 学习率、迭代次数和初始化方式对模型准确率的影响"
                        >
                            学习率、迭代次数和初始化方式对模型准确率的影响
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-10-29T04:46:50+08:00">
	
		    2016 年 10 月 29 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>想必学过机器学习的人都知道，学习率、训练迭代次数和模型参数的初始化方式都对模型最后的准确率有一定的影响，那么影响到底有多大呢？</p>
<p>我初步做了个实验，在 <code>TensorFlow</code> 框架下使用 Logistics Regression 对经典的 <code>MNIST</code> 数据集进行分类。</p>
                    
                        <a
                            href="/2016/10/29/tensorflow-hyperparams/"
                            class="postShorten-excerpt_link link"
                            aria-label=": 学习率、迭代次数和初始化方式对模型准确率的影响"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/10/22/tensorflow-linear-regression/"
                            aria-label=": TensorFlow 中的线性回归"
                        >
                            TensorFlow 中的线性回归
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-10-22T08:53:57+08:00">
	
		    2016 年 10 月 22 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>前面 <a href="http://blog.csdn.net/u010099080/article/details/52333935">有篇博文</a> 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。</p>
                    
                        <a
                            href="/2016/10/22/tensorflow-linear-regression/"
                            class="postShorten-excerpt_link link"
                            aria-label=": TensorFlow 中的线性回归"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="/2016/08/27/ubuntu-installing-tensorflow/"
                            aria-label=": Ubuntu 14.04 64 位安装 Google 的 TensorFlow"
                        >
                            Ubuntu 14.04 64 位安装 Google 的 TensorFlow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2016-08-27T10:23:48+08:00">
	
		    2016 年 8 月 27 日
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>今天来说一下机器学习库 TensorFlow 的在 Ubuntu14.04 64位下的安装。</p>
                    
                        <a
                            href="/2016/08/27/ubuntu-installing-tensorflow/"
                            class="postShorten-excerpt_link link"
                            aria-label=": Ubuntu 14.04 64 位安装 Google 的 TensorFlow"
                        >
                            阅读全文
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
          <li class="pagination-prev">
            <a
                class="btn btn--default btn--small"
                href="/tags/TensorFlow/"
                aria-label="上一页"
            >
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>上一页</span>
            </a>
          </li>
        
        
        <li class="pagination-number">第 2 页 共 2 页</li>
    </ul>
</div>

</section>


                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Alan Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
            <h4 id="about-card-name">Alan Lee</h4>
        
            <div id="about-card-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                北京
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://s2.loli.net/2021/12/16/5nuJTFWg2QACLDf.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-bzxavs3xgrmr4dhl4zkhmrmrloaxiygxfjiarsltzu6y5bjgj5wpgsicnjdf.min.js"></script>

<!--SCRIPTS END-->





    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
