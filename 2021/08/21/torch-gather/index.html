
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Alan Lee">
    <title>理解 PyTorch 中的 gather 函数 - Alan Lee</title>
    <meta name="author" content="Alan Lee">
    
        <meta name="keywords" content="hexo,python,tensorflow,pytorch,nlp,natural language processing,deep learning,machine learning,large language models,llms,">
    
    
        <link rel="icon" href="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png">
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"},"articleBody":"\n好久没更新博客了，最近一直在忙，既有生活上的也有工作上的。道阻且长啊。\n今天来水一文，说一说最近工作上遇到的一个函数：torch.gather() 。\n文字理解我遇到的代码是 NLP 相关的，代码中用 torch.gather() 来将一个 tensor 的 shape 从 (batch_size, seq_length, hidden_size) 转为 (batch_size, labels_length, hidden_size) ，其中 seq_length &gt;= labels_length 。\ntorch.gather() 的官方解释是\n\nGathers values along an axis specified by dim.\n\n就是在指定维度上 gather value。那么怎么 gather、gather 哪些 value 呢？这就要看其参数了。\ntorch.gather() 的必填也是最常用的参数有三个，下面引用官方解释：\n\ninput (Tensor) – the source tensor\ndim (int) – the axis along which to index\nindex (LongTensor) – the indices of elements to gather\n\n所以一句话概括 gather 操作就是：根据 index ，在 input 的 dim 维度上收集 value。\n具体来说，input 就是源 tensor，等会我们要在这个 tensor 上执行 gather 操作。如果 input 是一个一维数组，即 flat 列表，那么我们就可以直接根据 index 在 input 上取了，就像正常的列表/数组索引一样。但是由于 input 可能含有多个维度，是 N 维数组，所以我们需要知道在哪个维度上进行 gather，这就是 dim 的作用。\n对于 dim 参数，一种更为具体的理解方式是替换法。假设 input 和 index 均为三维数组，那么输出 tensor 每个位置的索引是列表 [i, j, k] ，正常来说我们直接取 input[i, j, k] 作为 输出 tensor 对应位置的值即可，但是由于 dim 的存在以及 input.shape 可能不等于 index.shape ，所以直接取值可能就会报 IndexError 。所以我们是将索引列表的相应位置替换为 dim ，再去 input 取值。如果 dim=0 ，我们就替换索引列表第 0 个值，即 [dim, j, k] ，依此类推。Pytorch 的官方文档也是这么写的：\n123out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n但是可能你还有点迷糊，没关系接着看下面的直观理解部分，然后再回来看这段话，结合着看，相信你很快能明白。\n由于我们是按照 index 来取值的，所以最终得到的 tensor 的 shape 也是和 index 一样的，就像我们在列表上按索引取值，得到的输出列表长度和索引相等一样。\n直观理解为便于理解，我们以一个具体例子来说明。我们使用反推法，根据 input 和输出推参数。这应该也是我们平常自己写代码的时候遇到比较多的情况。\n假设 input 和我们想要的输出 output 如下：\n1234567891011121314&gt;&gt;&gt; input_tensor = torch.arange(24).reshape(2, 3, 4)tensor([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],        [[12, 13, 14, 15],         [16, 17, 18, 19],         [20, 21, 22, 23]]])&gt;&gt;&gt; output_tensor  # shape: (2, 2, 4)tensor([[[ 0,  1,  2,  3],         [ 8,  9, 10, 11]],        [[12, 13, 14, 15],         [20, 21, 22, 23]]])\n 即，我们想让 shape 为 (2, 3, 4) 的 input_tensor 变成 shape 为 (2, 2, 4) 的 output_tensor ，丢弃维度 1 的第 2 个元素，即 [ 4,  5,  6,  7] 和 [16, 17, 18, 19] 。\n我们应用替换法，重点是找出来 dim 和 index 的值。始终记住 index 和 output_tensor 的 shape 是一样的。\n从 output_tensor 的第一个位置开始，由于 output_tensor[0, 0, :] = input_tensor[0, 0, :] ，所以此时 [i, j, k] 是一样的，我们看不出来 dim 应该是多少。\n下一行 output_tensor[0, 1, 0] = input_tensor[0, 2, 0] ，这里我们看到维度 1 发生了变化，1 变成了 2，所以 dim 应该是 1，而 index 应为 2， index_tensor[0, 1, 0]=2 。\n此时 dim 已经明确。同理，output_tensor[0, 1, 1] = input_tensor[0, 2, 1] ，index_tensor[0, 1, 1]=2 ，依此类推，得到 index_tensor[0, 1, :] = 2 。同时也可以明确 index_tensor[0, 0, :] = 0 。\n所以\n1234567&gt;&gt;&gt; dim = 0&gt;&gt;&gt; index_tensortensor([[[0, 0, 0, 0],         [2, 2, 2, 2]],        [[0, 0, 0, 0],         [2, 2, 2, 2]]])\n简单可描述如下图：\n\n为描述方便，假如我们把输入看作是 6 行，从上到下依次是 0-5。那么从事后诸葛亮的角度讲，输出相当于是把第 1 和第 4 行“抽掉”。如果输出和输入一样，那么原本的 index_tensor 就是如下：\n1234567tensor([[[0, 0, 0, 0],         [1, 1, 1, 1],         [2, 2, 2, 2]],        [[0, 0, 0, 0],         [1, 1, 1, 1],         [2, 2, 2, 2]]])\n“抽掉”后， index_tensor 也相应“抽掉”，那么就得到我们想要的结果了。而且由于这个“抽掉”的操作是在维度 1 上进行的，那么 dim 自然是 1。\nnumpy.take() 和 tf.gather 貌似也是同样功能，就不细说了。\nReference\ntorch.gather — PyTorch 1.9.0 documentation\nnumpy.take — NumPy v1.21 Manual\ntf.gather | TensorFlow Core v2.6.0\n\nEND","dateCreated":"2021-08-21T17:10:00+08:00","dateModified":"2025-06-14T20:46:16+08:00","datePublished":"2021-08-21T17:10:00+08:00","description":"\n好久没更新博客了，最近一直在忙，既有生活上的也有工作上的。道阻且长啊。","headline":"理解 PyTorch 中的 gather 函数","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://alanlee.fun/2021/08/21/torch-gather/"},"publisher":{"@type":"Organization","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png","logo":{"@type":"ImageObject","url":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"}},"url":"https://alanlee.fun/2021/08/21/torch-gather/","keywords":"Python, PyTorch"}</script>
    <meta name="description" content="好久没更新博客了，最近一直在忙，既有生活上的也有工作上的。道阻且长啊。">
<meta property="og:type" content="blog">
<meta property="og:title" content="理解 PyTorch 中的 gather 函数">
<meta property="og:url" content="https://alanlee.fun/2021/08/21/torch-gather/index.html">
<meta property="og:site_name" content="Alan Lee">
<meta property="og:description" content="好久没更新博客了，最近一直在忙，既有生活上的也有工作上的。道阻且长啊。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://alanlee.fun/2021/08/21/torch-gather/torch.gather%20%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B">
<meta property="article:published_time" content="2021-08-21T09:10:00.000Z">
<meta property="article:modified_time" content="2025-06-14T12:46:16.199Z">
<meta property="article:author" content="Alan Lee">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://alanlee.fun/2021/08/21/torch-gather/torch.gather%20%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B">
<meta name="twitter:creator" content="@bluekirin93">
    
    
        
    
    
        <meta property="og:image" content="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-7psn7jtnqx8dcatt1chsgye58vhpeeqkf8gzcb5iijzope7gwcvezy8gigh2.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111553531-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111553531-1');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
        
    
    <style>
        ::-moz-selection { /* Code for Firefox */
          background: #FFBFBF;
        }
        
        ::selection {
          background: #FFBFBF;
        }
    </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Alan Lee
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Alan Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/secsilm"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/bluekirin93"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:secsilm@outlook.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            理解 PyTorch 中的 gather 函数
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2021-08-21T17:10:00+08:00">
	
		    2021 年 8 月 21 日
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h1 id="table-of-contents">目录</h1><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E5%AD%97%E7%90%86%E8%A7%A3"><span class="toc-text">文字理解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3"><span class="toc-text">直观理解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-text">Reference</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#END"><span class="toc-text">END</span></a></li></ol>
<p>好久没更新博客了，最近一直在忙，既有生活上的也有工作上的。道阻且长啊。<br><span id="more"></span></p>
<p>今天来水一文，说一说最近工作上遇到的一个函数：<a href="https://pytorch.org/docs/stable/generated/torch.gather.html"><code>torch.gather()</code></a> 。</p>
<h2 id="文字理解"><a href="#文字理解" class="headerlink" title="文字理解"></a>文字理解</h2><p>我遇到的代码是 NLP 相关的，代码中用 <code>torch.gather()</code> 来将一个 tensor 的 shape 从 <code>(batch_size, seq_length, hidden_size)</code> 转为 <code>(batch_size, labels_length, hidden_size)</code> ，其中 <code>seq_length &gt;= labels_length</code> 。</p>
<p><code>torch.gather()</code> 的官方解释是</p>
<blockquote>
<p>Gathers values along an axis specified by <em>dim</em>.</p>
</blockquote>
<p>就是在指定维度上 gather value。那么怎么 gather、gather 哪些 value 呢？这就要看其参数了。</p>
<p><code>torch.gather()</code> 的必填也是最常用的参数有三个，下面引用官方解释：</p>
<ul>
<li><code>input</code> (<em><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></em>) – the source tensor</li>
<li><code>dim</code> (<em><a href="https://docs.python.org/3/library/functions.html#int">int</a></em>) – the axis along which to index</li>
<li><code>index</code> (<em>LongTensor</em>) – the indices of elements to gather</li>
</ul>
<p>所以一句话概括 gather 操作就是：<strong>根据 <code>index</code> ，在 <code>input</code> 的 <code>dim</code> 维度上收集 value</strong>。</p>
<p>具体来说，<code>input</code> 就是源 tensor，等会我们要在这个 tensor 上执行 gather 操作。如果 <code>input</code> 是一个一维数组，即 flat 列表，那么我们就可以直接根据 <code>index</code> 在 <code>input</code> 上取了，就像正常的列表/数组索引一样。但是由于 <code>input</code> 可能含有多个维度，是 N 维数组，所以我们需要知道在哪个维度上进行 gather，这就是 <code>dim</code> 的作用。</p>
<p>对于 <code>dim</code> 参数，一种更为具体的理解方式是<strong>替换法</strong>。假设 <code>input</code> 和 <code>index</code> 均为三维数组，那么输出 tensor 每个位置的索引是列表 <code>[i, j, k]</code> ，正常来说我们直接取 <code>input[i, j, k]</code> 作为 输出 tensor 对应位置的值即可，但是由于 <code>dim</code> 的存在以及 <code>input.shape</code> 可能不等于 <code>index.shape</code> ，所以直接取值可能就会报 <code>IndexError</code> 。所以我们是将索引列表的相应位置替换为 <code>dim</code> ，再去 <code>input</code> 取值。如果 <code>dim=0</code> ，我们就替换索引列表第 0 个值，即 <code>[dim, j, k]</code> ，依此类推。Pytorch 的官方文档也是这么写的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][index[i][j][k]][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][j][index[i][j][k]]  <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure>
<p>但是可能你还有点迷糊，没关系接着看下面的直观理解部分，然后再回来看这段话，结合着看，相信你很快能明白。</p>
<p>由于我们是按照 <code>index</code> 来取值的，所以最终得到的 tensor 的 shape 也是和 <code>index</code> 一样的，就像我们在列表上按索引取值，得到的输出列表长度和索引相等一样。</p>
<h2 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h2><p>为便于理解，我们以一个具体例子来说明。我们使用反推法，根据 <code>input</code> 和输出推参数。这应该也是我们平常自己写代码的时候遇到比较多的情况。</p>
<p>假设 <code>input</code> 和我们想要的输出 <code>output</code> 如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input_tensor = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">         [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">         [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output_tensor  <span class="comment"># shape: (2, 2, 4)</span></span><br><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br></pre></td></tr></table></figure>
<p> 即，我们想让 shape 为 <code>(2, 3, 4)</code> 的 <code>input_tensor</code> 变成 shape 为 <code>(2, 2, 4)</code> 的 <code>output_tensor</code> ，丢弃维度 1 的第 2 个元素，即 <code>[ 4,  5,  6,  7]</code> 和 <code>[16, 17, 18, 19]</code> 。</p>
<p>我们应用替换法，重点是找出来 <code>dim</code> 和 <code>index</code> 的值。始终记住 <code>index</code> 和 <code>output_tensor</code> 的 shape 是一样的。</p>
<p>从 <code>output_tensor</code> 的第一个位置开始，由于 <code>output_tensor[0, 0, :] = input_tensor[0, 0, :]</code> ，所以此时 <code>[i, j, k]</code> 是一样的，我们看不出来 <code>dim</code> 应该是多少。</p>
<p>下一行 <code>output_tensor[0, 1, 0] = input_tensor[0, 2, 0]</code> ，这里我们看到维度 1 发生了变化，1 变成了 2，所以 <code>dim</code> 应该是 1，而 <code>index</code> 应为 2， <code>index_tensor[0, 1, 0]=2</code> 。</p>
<p>此时 <code>dim</code> 已经明确。同理，<code>output_tensor[0, 1, 1] = input_tensor[0, 2, 1]</code> ，<code>index_tensor[0, 1, 1]=2</code> ，依此类推，得到 <code>index_tensor[0, 1, :] = 2</code> 。同时也可以明确 <code>index_tensor[0, 0, :] = 0</code> 。</p>
<p>所以</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dim = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index_tensor</span><br><span class="line">tensor([[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]])</span><br></pre></td></tr></table></figure>
<p>简单可描述如下图：</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://i.loli.net/2021/08/21/FexGTLdhCrfqZWB.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="torch.gather 执行过程" alt=""></a></div>
<p>为描述方便，假如我们把输入看作是 6 行，从上到下依次是 0-5。那么从事后诸葛亮的角度讲，输出相当于是把第 1 和第 4 行“抽掉”。如果输出和输入一样，那么原本的 <code>index_tensor</code> 就是如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]])</span><br></pre></td></tr></table></figure>
<p>“抽掉”后， <code>index_tensor</code> 也相应“抽掉”，那么就得到我们想要的结果了。而且由于这个“抽掉”的操作是在维度 1 上进行的，那么 <code>dim</code> 自然是 1。</p>
<p><code>numpy.take()</code> 和 <code>tf.gather</code> 貌似也是同样功能，就不细说了。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.gather.html">torch.gather — PyTorch 1.9.0 documentation</a></li>
<li><a href="https://numpy.org/doc/stable/reference/generated/numpy.take.html">numpy.take — NumPy v1.21 Manual</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/gather">tf.gather | TensorFlow Core v2.6.0</a></li>
</ul>
<h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/PyTorch/" rel="tag">PyTorch</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Python/" rel="tag">Python</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2021/09/12/data-augment-ner-nlp/"
                    data-tooltip="NLP 中的通用数据增强方法及针对 NER 的变种"
                    aria-label="上一篇: NLP 中的通用数据增强方法及针对 NER 的变种"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2021/05/01/ghost-ssl-cert/"
                    data-tooltip="Ghost SSL 证书过期的解决办法"
                    aria-label="下一篇: Ghost SSL 证书过期的解决办法"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2021/08/21/torch-gather/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2021/08/21/torch-gather/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2021/08/21/torch-gather/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Alan Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2021/09/12/data-augment-ner-nlp/"
                    data-tooltip="NLP 中的通用数据增强方法及针对 NER 的变种"
                    aria-label="上一篇: NLP 中的通用数据增强方法及针对 NER 的变种"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2021/05/01/ghost-ssl-cert/"
                    data-tooltip="Ghost SSL 证书过期的解决办法"
                    aria-label="下一篇: Ghost SSL 证书过期的解决办法"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2021/08/21/torch-gather/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2021/08/21/torch-gather/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2021/08/21/torch-gather/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2021/08/21/torch-gather/"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2021/08/21/torch-gather/"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2021/08/21/torch-gather/"
                        aria-label="分享到 Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>分享到 Weibo</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
            <h4 id="about-card-name">Alan Lee</h4>
        
            <div id="about-card-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                北京
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://s2.loli.net/2021/12/16/5nuJTFWg2QACLDf.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-bzxavs3xgrmr4dhl4zkhmrmrloaxiygxfjiarsltzu6y5bjgj5wpgsicnjdf.min.js"></script>

<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://alanlee.fun/2021/08/21/torch-gather/';
              
            this.page.identifier = '2021/08/21/torch-gather/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'secsilm';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
