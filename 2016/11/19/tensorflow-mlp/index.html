
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Alan Lee">
    <title>TensorFlow 中的多层感知器（MLP） - Alan Lee</title>
    <meta name="author" content="Alan Lee">
    
        <meta name="keywords" content="hexo,python,tensorflow,pytorch,nlp,natural language processing,deep learning,machine learning,large language models,llms,">
    
    
        <link rel="icon" href="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png">
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"},"articleBody":"前面有几篇博文讲了使用 TensorFlow 实现线性回归和逻辑斯蒂回归，这次来说下多层感知器（Multi-Layer Perceptron）的 TensorFlow 实现。\n本篇博文的代码及结果图片等可以在这里下载，里面包含TensorFlow的实现和sklearn的实现，以及各自的结果图片。\n\n\n原理\n多层感知器（Multilayer Perceptron,缩写MLP）是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。\n\n关于 MLP 的原理我就不再赘述，我用下面的一个图来简单说明下：\n\n如上图，实际上这就是一个前馈神经网络，我画的就是本篇博文所使用的结构（粗心少画了一层隐藏层，实际上使用的是3层隐藏层……）：\n\n输入层：有 3072 个输入神经元，$m=3072$\n隐藏层：有两层（三层）隐藏层，每个隐藏层有 1024 个神经元，$ p=q=1024$；\n输出层：有10个神经元，$n=10$\n\n输入层和输出层的神经元个数，是根据数据集来定的，而隐藏层的层数和每层隐藏层的神经元个数，这些都属于超参数（hyperparameter），是事先通过某种方法确定的。\n\n数据集这次采用的数据集是著名的 CIFAR-10 图像数据集，包含 60000 张 32×32 的彩色RGB图像，共有 10 类，每类有 6000 张图像。完整数据集可以从这里下载，注意选择 Python 版本，大概是 163 MB。\n下载好后解压会看到有5个训练文件和1个测试文件，还有一个说明文件（batches.meta），这个文件说明了每个数字类别（0-9）具体代表哪些类别。这几个文件都是用 cPickle 打包好的，所以载入数据也要用 cPickle 来载入。注意Python2和Python3的载入方式稍微有些不同，具体见代码。\n目前在此数据集上做的实验在没有数据增加的情况下最低的错误率是 18%，数据增加的情况下最低的错误率是 11%，都是采用的卷积神经网络（CNN）的结构。\n数据集中的图像和分类大致是这样的：\n\n\n代码以下代码的运行环境是 Python2 + Ubuntu14.04 + Jupyter Notebook。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133from __future__ import print_functionimport tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltimport cPickle as pickle# seaborn非必需import seaborn# 如果不是在Jupyter Notebook上运行的话请注释掉下面这句%matplotlib inlinedef unpickle(filename):\t&#x27;&#x27;&#x27; 解压数据 &#x27;&#x27;&#x27;    with open(filename) as f:        # for python3         # d = pickle.load(f, encoding=&#x27;latin1&#x27;)        d = pickle.load(f)        return ddef onehot(labels):\t&#x27;&#x27;&#x27; one-hot 编码 &#x27;&#x27;&#x27;    n_sample = len(labels)    n_class = max(labels) + 1    onehot_labels = np.zeros((n_sample, n_class))    onehot_labels[np.arange(n_sample), labels] = 1        return onehot_labels# 读取数据data1 = unpickle(&#x27;cifar-10-batches-py/data_batch_1&#x27;)data2 = unpickle(&#x27;cifar-10-batches-py/data_batch_2&#x27;)data3 = unpickle(&#x27;cifar-10-batches-py/data_batch_3&#x27;)data4 = unpickle(&#x27;cifar-10-batches-py/data_batch_4&#x27;)data5 = unpickle(&#x27;cifar-10-batches-py/data_batch_5&#x27;)X_train = np.concatenate((data1[&#x27;data&#x27;], data2[&#x27;data&#x27;], data3[&#x27;data&#x27;], data4[&#x27;data&#x27;], data5[&#x27;data&#x27;]), axis=0)label = np.concatenate((data1[&#x27;labels&#x27;], data2[&#x27;labels&#x27;], data3[&#x27;labels&#x27;], data4[&#x27;labels&#x27;], data5[&#x27;labels&#x27;]), axis=0)y_train = onehot(label)test = unpickle(&#x27;cifar-10-batches-py/test_batch&#x27;)X_test = test[&#x27;data&#x27;]y_test = onehot(test[&#x27;labels&#x27;])# 设置模型参数learning_rate = 0.001training_epochs = 500batch_size = 500display_step = 1n_sample = X_train.shape[0]n_input = X_train.shape[1]n_hidden_1 = 1024n_hidden_2 = 1024n_hidden_3 = 1024n_class = y_train.shape[1]x = tf.placeholder(&#x27;float&#x27;, [None, n_input])y = tf.placeholder(&#x27;float&#x27;, [None, n_class])def multiplayer_perceptron(x, weight, bias):        layer1 = tf.add(tf.matmul(x, weight[&#x27;h1&#x27;]), bias[&#x27;h1&#x27;])    layer1 = tf.nn.relu(layer1)    layer2 = tf.add(tf.matmul(layer1, weight[&#x27;h2&#x27;]), bias[&#x27;h2&#x27;])    layer2 = tf.nn.relu(layer2)    layer3 = tf.add(tf.matmul(layer2, weight[&#x27;h3&#x27;]), bias[&#x27;h3&#x27;])    layer3 = tf.nn.relu(layer3)    out_layer = tf.add(tf.matmul(layer3, weight[&#x27;out&#x27;]), bias[&#x27;out&#x27;])        return out_layerweight = &#123;    &#x27;h1&#x27;: tf.Variable(tf.random_normal([n_input, n_hidden_1])),    &#x27;h2&#x27;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),     &#x27;h3&#x27;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),     &#x27;out&#x27;: tf.Variable(tf.random_normal([n_hidden_3, n_class]))&#125;bias = &#123;    &#x27;h1&#x27;: tf.Variable(tf.random_normal([n_hidden_1])),    &#x27;h2&#x27;: tf.Variable(tf.random_normal([n_hidden_2])),     &#x27;h3&#x27;: tf.Variable(tf.random_normal([n_hidden_3])),     &#x27;out&#x27;: tf.Variable(tf.random_normal([n_class]))&#125;# 建立模型pred = multiplayer_perceptron(x, weight, bias)# 定义损失函数cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))# 优化optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)# 初始化所有变量init = tf.initialize_all_variables()correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, &#x27;float&#x27;))# 训练模型with tf.Session() as sess:    sess.run(init)        for epoch in range(training_epochs):        avg_cost = 0        total_batch = int(n_sample / batch_size)                for i in range(total_batch):            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: X_train[i*batch_size : (i+1)*batch_size, :],                                                           y: y_train[i*batch_size : (i+1)*batch_size, :]&#125;)            avg_cost += c / total_batch                plt.plot(epoch+1, avg_cost, &#x27;co&#x27;)                if epoch % display_step == 0:            print(&#x27;Epoch:&#x27;, &#x27;%04d&#x27; % (epoch+1), &#x27;cost=&#x27;, &#x27;&#123;:.9f&#125;&#x27;.format(avg_cost))                print(&#x27;Opitimization Finished!&#x27;)        # Test    acc = accuracy.eval(&#123;x: X_test, y: y_test&#125;)    print(&#x27;Accuracy:&#x27;, acc)        plt.xlabel(&#x27;Epoch&#x27;)    plt.ylabel(&#x27;Cost&#x27;)    plt.title(&#x27;lr=%f, te=%d, bs=%d, acc=%f&#x27; % (learning_rate, training_epochs, batch_size, acc))    plt.tight_layout()    plt.savefig(&#x27;cifar-10-batches-py/MLP-TF14-test.png&#x27;, dpi=200)        plt.show()\n\n结果由于进行了500次迭代，结果太多，这里我就不一一列出了，完整的可以在这里连带代码一起下载，里面也包含了我测试不同超参数组合的结果图。\n下面给出本次实验的结果图：\n\n其中的缩写仍然遵照我以前博文的习惯，\n\nlr：learning rate，学习率\ntr：training epochs，训练迭代次数\nbs：batch size，batch大小\nacc：测试准确率\n\n可以看到最终的准确率是 46.98%，如前所述，目前此数据集上最好的结果是 82%，用的是对图像识别有巨大优势的卷积神经网络。当然，使用更深层的MLP也会提高准确率。\n\n一些问题\n学习率不能过大，这里使用的 0.001 已经是极限，其他参数不变的情况下，再大例如 0.01，准确率会大幅下跌，跌至 10% 左右，此时无论再怎么增加迭代次数准确率（包括训练准确率）也不会提高，一直在 10% 左右，但是损失却降得很厉害，此处还未彻底搞清楚。\n我使用sklearn也测试了一下（代码下载链接和上面一样），最终准确率 46.25%。\n本片博文只是为了说明如何使用 TensorFlow 实现MLP，本次做的实验并不一定是最优的实验结果。\n这篇博文 同样使用CIFAR10数据集但是使用CNN模型，可以和本文做个对比。\n\n\n\nEND","dateCreated":"2016-11-19T08:56:14+08:00","dateModified":"2025-06-14T20:46:16+08:00","datePublished":"2016-11-19T08:56:14+08:00","description":"前面有几篇博文讲了使用 TensorFlow 实现线性回归和逻辑斯蒂回归，这次来说下多层感知器（Multi-Layer Perceptron）的 TensorFlow 实现。\n本篇博文的代码及结果图片等可以在这里下载，里面包含TensorFlow的实现和sklearn的实现，以及各自的结果图片。","headline":"TensorFlow 中的多层感知器（MLP）","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://alanlee.fun/2016/11/19/tensorflow-mlp/"},"publisher":{"@type":"Organization","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png","logo":{"@type":"ImageObject","url":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"}},"url":"https://alanlee.fun/2016/11/19/tensorflow-mlp/","keywords":"Python, TensorFlow, Machine Learning"}</script>
    <meta name="description" content="前面有几篇博文讲了使用 TensorFlow 实现线性回归和逻辑斯蒂回归，这次来说下多层感知器（Multi-Layer Perceptron）的 TensorFlow 实现。 本篇博文的代码及结果图片等可以在这里下载，里面包含TensorFlow的实现和sklearn的实现，以及各自的结果图片。">
<meta property="og:type" content="blog">
<meta property="og:title" content="TensorFlow 中的多层感知器（MLP）">
<meta property="og:url" content="https://alanlee.fun/2016/11/19/tensorflow-mlp/index.html">
<meta property="og:site_name" content="Alan Lee">
<meta property="og:description" content="前面有几篇博文讲了使用 TensorFlow 实现线性回归和逻辑斯蒂回归，这次来说下多层感知器（Multi-Layer Perceptron）的 TensorFlow 实现。 本篇博文的代码及结果图片等可以在这里下载，里面包含TensorFlow的实现和sklearn的实现，以及各自的结果图片。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://i.imgur.com/IYMbvtU.png">
<meta property="og:image" content="http://i.imgur.com/Rzsw6mo.png">
<meta property="og:image" content="http://i.imgur.com/mLZ5ALb.png">
<meta property="article:published_time" content="2016-11-19T00:56:14.000Z">
<meta property="article:modified_time" content="2025-06-14T12:46:16.199Z">
<meta property="article:author" content="Alan Lee">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="TensorFlow">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://i.imgur.com/IYMbvtU.png">
<meta name="twitter:creator" content="@bluekirin93">
    
    
        
    
    
        <meta property="og:image" content="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-7psn7jtnqx8dcatt1chsgye58vhpeeqkf8gzcb5iijzope7gwcvezy8gigh2.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111553531-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111553531-1');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
        
    
    <style>
        ::-moz-selection { /* Code for Firefox */
          background: #FFBFBF;
        }
        
        ::selection {
          background: #FFBFBF;
        }
    </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Alan Lee
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Alan Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/secsilm"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/bluekirin93"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:secsilm@outlook.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            TensorFlow 中的多层感知器（MLP）
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2016-11-19T08:56:14+08:00">
	
		    2016 年 11 月 19 日
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>前面有几篇博文讲了使用 <code>TensorFlow</code> 实现<a href="http://blog.csdn.net/u010099080/article/details/52894773">线性回归</a>和<a href="http://blog.csdn.net/u010099080/article/details/53054519">逻辑斯蒂回归</a>，这次来说下多层感知器（Multi-Layer Perceptron）的 <code>TensorFlow</code> 实现。</p>
<p><strong>本篇博文的代码及结果图片等可以在<a href="http://download.csdn.net/download/u010099080/9687585">这里</a>下载，里面包含TensorFlow的实现和sklearn的实现，以及各自的结果图片。</strong></p>
<span id="more"></span>
<hr>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><blockquote>
<p>多层感知器（Multilayer Perceptron,缩写MLP）是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。</p>
</blockquote>
<p>关于 MLP 的原理我就不再赘述，我用下面的一个图来简单说明下：</p>
<p><img src="http://i.imgur.com/IYMbvtU.png" alt=""></p>
<p>如上图，实际上这就是一个前馈神经网络，我画的就是本篇博文所使用的结构（<em>粗心少画了一层隐藏层，实际上使用的是3层隐藏层……</em>）：</p>
<ol>
<li>输入层：有 3072 个输入神经元，$m=3072$</li>
<li>隐藏层：有两层（三层）隐藏层，每个隐藏层有 1024 个神经元，$ p=q=1024$；</li>
<li>输出层：有10个神经元，$n=10$</li>
</ol>
<p>输入层和输出层的神经元个数，是根据数据集来定的，而隐藏层的层数和每层隐藏层的神经元个数，这些都属于超参数（hyperparameter），是事先通过某种方法确定的。</p>
<hr>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>这次采用的数据集是著名的 <code>CIFAR-10</code> 图像数据集，包含 <strong>60000</strong> 张 <strong>32×32</strong> 的彩色RGB图像，共有 <strong>10</strong> 类，每类有 <strong>6000</strong> 张图像。完整数据集可以从<a href="https://www.cs.toronto.edu/~kriz/cifar.html">这里</a>下载，注意选择 Python 版本，大概是 163 MB。</p>
<p>下载好后解压会看到有5个训练文件和1个测试文件，还有一个说明文件（<code>batches.meta</code>），这个文件说明了每个数字类别（0-9）具体代表哪些类别。这几个文件都是用 <code>cPickle</code> 打包好的，所以载入数据也要用 <code>cPickle</code> 来载入。注意Python2和Python3的载入方式稍微有些不同，具体见代码。</p>
<p>目前在此数据集上做的实验在没有数据增加的情况下最低的错误率是 <strong>18%</strong>，数据增加的情况下最低的错误率是 <strong>11%</strong>，都是采用的卷积神经网络（CNN）的结构。</p>
<p>数据集中的图像和分类大致是这样的：</p>
<p><img src="http://i.imgur.com/Rzsw6mo.png" alt=""></p>
<hr>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>以下代码的运行环境是 <em>Python2 + Ubuntu14.04 + Jupyter Notebook</em>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle</span><br><span class="line"><span class="comment"># seaborn非必需</span></span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line"><span class="comment"># 如果不是在Jupyter Notebook上运行的话请注释掉下面这句</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unpickle</span>(<span class="params">filename</span>):</span><br><span class="line">	<span class="string">&#x27;&#x27;&#x27; 解压数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># for python3 </span></span><br><span class="line">        <span class="comment"># d = pickle.load(f, encoding=&#x27;latin1&#x27;)</span></span><br><span class="line">        d = pickle.load(f)</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">onehot</span>(<span class="params">labels</span>):</span><br><span class="line">	<span class="string">&#x27;&#x27;&#x27; one-hot 编码 &#x27;&#x27;&#x27;</span></span><br><span class="line">    n_sample = <span class="built_in">len</span>(labels)</span><br><span class="line">    n_class = <span class="built_in">max</span>(labels) + <span class="number">1</span></span><br><span class="line">    onehot_labels = np.zeros((n_sample, n_class))</span><br><span class="line">    onehot_labels[np.arange(n_sample), labels] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> onehot_labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data1 = unpickle(<span class="string">&#x27;cifar-10-batches-py/data_batch_1&#x27;</span>)</span><br><span class="line">data2 = unpickle(<span class="string">&#x27;cifar-10-batches-py/data_batch_2&#x27;</span>)</span><br><span class="line">data3 = unpickle(<span class="string">&#x27;cifar-10-batches-py/data_batch_3&#x27;</span>)</span><br><span class="line">data4 = unpickle(<span class="string">&#x27;cifar-10-batches-py/data_batch_4&#x27;</span>)</span><br><span class="line">data5 = unpickle(<span class="string">&#x27;cifar-10-batches-py/data_batch_5&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X_train = np.concatenate((data1[<span class="string">&#x27;data&#x27;</span>], data2[<span class="string">&#x27;data&#x27;</span>], data3[<span class="string">&#x27;data&#x27;</span>], data4[<span class="string">&#x27;data&#x27;</span>], data5[<span class="string">&#x27;data&#x27;</span>]), axis=<span class="number">0</span>)</span><br><span class="line">label = np.concatenate((data1[<span class="string">&#x27;labels&#x27;</span>], data2[<span class="string">&#x27;labels&#x27;</span>], data3[<span class="string">&#x27;labels&#x27;</span>], data4[<span class="string">&#x27;labels&#x27;</span>], data5[<span class="string">&#x27;labels&#x27;</span>]), axis=<span class="number">0</span>)</span><br><span class="line">y_train = onehot(label)</span><br><span class="line"></span><br><span class="line">test = unpickle(<span class="string">&#x27;cifar-10-batches-py/test_batch&#x27;</span>)</span><br><span class="line">X_test = test[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y_test = onehot(test[<span class="string">&#x27;labels&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置模型参数</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">training_epochs = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">500</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line">n_sample = X_train.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">n_input = X_train.shape[<span class="number">1</span>]</span><br><span class="line">n_hidden_1 = <span class="number">1024</span></span><br><span class="line">n_hidden_2 = <span class="number">1024</span></span><br><span class="line">n_hidden_3 = <span class="number">1024</span></span><br><span class="line">n_class = y_train.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(<span class="string">&#x27;float&#x27;</span>, [<span class="literal">None</span>, n_input])</span><br><span class="line">y = tf.placeholder(<span class="string">&#x27;float&#x27;</span>, [<span class="literal">None</span>, n_class])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multiplayer_perceptron</span>(<span class="params">x, weight, bias</span>):</span><br><span class="line">    </span><br><span class="line">    layer1 = tf.add(tf.matmul(x, weight[<span class="string">&#x27;h1&#x27;</span>]), bias[<span class="string">&#x27;h1&#x27;</span>])</span><br><span class="line">    layer1 = tf.nn.relu(layer1)</span><br><span class="line">    layer2 = tf.add(tf.matmul(layer1, weight[<span class="string">&#x27;h2&#x27;</span>]), bias[<span class="string">&#x27;h2&#x27;</span>])</span><br><span class="line">    layer2 = tf.nn.relu(layer2)</span><br><span class="line">    layer3 = tf.add(tf.matmul(layer2, weight[<span class="string">&#x27;h3&#x27;</span>]), bias[<span class="string">&#x27;h3&#x27;</span>])</span><br><span class="line">    layer3 = tf.nn.relu(layer3)</span><br><span class="line">    out_layer = tf.add(tf.matmul(layer3, weight[<span class="string">&#x27;out&#x27;</span>]), bias[<span class="string">&#x27;out&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> out_layer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">weight = &#123;</span><br><span class="line">    <span class="string">&#x27;h1&#x27;</span>: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">    <span class="string">&#x27;h2&#x27;</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), </span><br><span class="line">    <span class="string">&#x27;h3&#x27;</span>: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])), </span><br><span class="line">    <span class="string">&#x27;out&#x27;</span>: tf.Variable(tf.random_normal([n_hidden_3, n_class]))</span><br><span class="line">&#125;</span><br><span class="line">bias = &#123;</span><br><span class="line">    <span class="string">&#x27;h1&#x27;</span>: tf.Variable(tf.random_normal([n_hidden_1])),</span><br><span class="line">    <span class="string">&#x27;h2&#x27;</span>: tf.Variable(tf.random_normal([n_hidden_2])), </span><br><span class="line">    <span class="string">&#x27;h3&#x27;</span>: tf.Variable(tf.random_normal([n_hidden_3])), </span><br><span class="line">    <span class="string">&#x27;out&#x27;</span>: tf.Variable(tf.random_normal([n_class]))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">pred = multiplayer_perceptron(x, weight, bias)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化所有变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">&#x27;float&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0</span></span><br><span class="line">        total_batch = <span class="built_in">int</span>(n_sample / batch_size)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(total_batch):</span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: X_train[i*batch_size : (i+<span class="number">1</span>)*batch_size, :], </span><br><span class="line">                                                          y: y_train[i*batch_size : (i+<span class="number">1</span>)*batch_size, :]&#125;)</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        </span><br><span class="line">        plt.plot(epoch+<span class="number">1</span>, avg_cost, <span class="string">&#x27;co&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#x27;</span>, <span class="string">&#x27;%04d&#x27;</span> % (epoch+<span class="number">1</span>), <span class="string">&#x27;cost=&#x27;</span>, <span class="string">&#x27;&#123;:.9f&#125;&#x27;</span>.<span class="built_in">format</span>(avg_cost))</span><br><span class="line">            </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Opitimization Finished!&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Test</span></span><br><span class="line">    acc = accuracy.<span class="built_in">eval</span>(&#123;x: X_test, y: y_test&#125;)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy:&#x27;</span>, acc)</span><br><span class="line">    </span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;lr=%f, te=%d, bs=%d, acc=%f&#x27;</span> % (learning_rate, training_epochs, batch_size, acc))</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;cifar-10-batches-py/MLP-TF14-test.png&#x27;</span>, dpi=<span class="number">200</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>由于进行了500次迭代，结果太多，这里我就不一一列出了，完整的可以在<a href="http://download.csdn.net/download/u010099080/9687585">这里</a>连带代码一起下载，里面也包含了我测试不同超参数组合的结果图。</p>
<p>下面给出本次实验的结果图：</p>
<p><img src="http://i.imgur.com/mLZ5ALb.png" alt=""></p>
<p>其中的缩写仍然遵照我以前博文的习惯，</p>
<ul>
<li><code>lr</code>：learning rate，学习率</li>
<li><code>tr</code>：training epochs，训练迭代次数</li>
<li><code>bs</code>：batch size，batch大小</li>
<li><code>acc</code>：测试准确率</li>
</ul>
<p>可以看到最终的准确率是 46.98%，如前所述，目前此数据集上最好的结果是 82%，用的是对图像识别有巨大优势的卷积神经网络。当然，使用更深层的MLP也会提高准确率。</p>
<hr>
<h1 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h1><ol>
<li>学习率不能过大，这里使用的 0.001 已经是极限，其他参数不变的情况下，再大例如 0.01，准确率会大幅下跌，跌至 10% 左右，此时无论再怎么增加迭代次数准确率（包括训练准确率）也不会提高，一直在 10% 左右，但是损失却降得很厉害，此处还未彻底搞清楚。</li>
<li>我使用sklearn也测试了一下（代码下载链接和上面一样），最终准确率 46.25%。</li>
<li>本片博文只是为了说明如何使用 TensorFlow 实现MLP，本次做的实验并不一定是最优的实验结果。</li>
<li><a href="http://blog.csdn.net/u010099080/article/details/53906810">这篇博文</a> 同样使用CIFAR10数据集但是使用CNN模型，可以和本文做个对比。</li>
</ol>
<hr>
<h1 id="table-of-contents">目录</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-text">原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-text">代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-text">结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="toc-text">一些问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#END"><span class="toc-text">END</span></a></li></ol>
<h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1><!-- more -->
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Python/" rel="tag">Python</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/12/01/installing-tensorflow/"
                    data-tooltip="Windows10 64 位下安装 TensorFlow - 官方原生支持"
                    aria-label="上一篇: Windows10 64 位下安装 TensorFlow - 官方原生支持"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/11/06/tensorflow-logistic-regression/"
                    data-tooltip="TensorFlow 中的 Logistic Regression"
                    aria-label="下一篇: TensorFlow 中的 Logistic Regression"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Alan Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/12/01/installing-tensorflow/"
                    data-tooltip="Windows10 64 位下安装 TensorFlow - 官方原生支持"
                    aria-label="上一篇: Windows10 64 位下安装 TensorFlow - 官方原生支持"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/11/06/tensorflow-logistic-regression/"
                    data-tooltip="TensorFlow 中的 Logistic Regression"
                    aria-label="下一篇: TensorFlow 中的 Logistic Regression"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/11/19/tensorflow-mlp/"
                        aria-label="分享到 Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>分享到 Weibo</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
            <h4 id="about-card-name">Alan Lee</h4>
        
            <div id="about-card-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                北京
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://s2.loli.net/2021/12/16/5nuJTFWg2QACLDf.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-bzxavs3xgrmr4dhl4zkhmrmrloaxiygxfjiarsltzu6y5bjgj5wpgsicnjdf.min.js"></script>

<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://alanlee.fun/2016/11/19/tensorflow-mlp/';
              
            this.page.identifier = '2016/11/19/tensorflow-mlp/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'secsilm';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
