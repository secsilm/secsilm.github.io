<!DOCTYPE html>
<html>
    <head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" >
    <title>
        
        TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版 · Lee&#39;s Space Station
        
    </title>
    <link rel="icon" href= /avatar/Bastion_cute.png>
    <!-- TODO: 在font-face加载完毕后改变字体  -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.28/webfontloader.js"></script>
    <!-- 提前加载place holder  -->
    <style type="text/css">
        @font-face {
            font-family: 'Oswald-Regular';
            src: url(/font/Oswald-Regular.ttf);
        }
    </style>
    <style type="text/css">
        .site-intro {
            position: relative;
            width: 100%;
            height: 50vh;
            overflow: hidden;
            box-shadow: -0.1rem 0 0.5rem 0 rgba(0, 0, 0, 0.8);
        }
        .site-intro-placeholder {
            position: absolute;
            z-index: -2;
            top: 0;
            left: 0px;
            width: calc(100% + 300px);
            height: 100%;
            background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
            background-position: center center;
            transform: translate3d(-226px, 0, 0);
            animation: gradient-move 2.5s ease-out 0s 1;
        }
        @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>
    <link rel="stylesheet" href = /css/style.css?v=20171218 />
    <script src="//cdn.staticfile.org/jquery/3.2.1/jquery.min.js" defer></script>
    
    <script src="/scripts/main.js" defer></script>
    <!-- 百度统计  -->
    
    <script>
        var _hmt = _hmt || [];
        (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
    <!-- 谷歌统计  -->
    
    <script>
        (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-111553531-1', 'auto');
        ga('send', 'pageview');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>
    
        <body class="post-body">
    
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Lee&#39;s Space Station</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Lee's Space Station</a>
</header>
    <div class="wrapper">
        <div class="site-intro">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-img" style="background-image: url(/assets/hanamura.jpg)"></div>
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <!-- 文章页标签  -->
            
                <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-href = Machine Learning>Machine Learning</a>
    
        <a class="post-tag" href="javascript:void(0);" data-href = Python>Python</a>
    
        <a class="post-tag" href="javascript:void(0);" data-href = TensorFlow>TensorFlow</a>
    
</div>
            
            <div class="post-intro-meta">
                <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                <span class="post-intro-time">2016/12/28</span>
            </div>
        
    </div>
</div>
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <script>
            var browser = {
                    versions: function () {
                        var u = window.navigator.userAgent;
                        return {
                            userAgent: u,
                            trident: u.indexOf('Trident') > -1, //IE内核
                            presto: u.indexOf('Presto') > -1, //opera内核
                            webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
                            gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
                            mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
                            ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
                            android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
                            iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
                            iPad: u.indexOf('iPad') > -1, //是否为iPad
                            webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
                            weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
                            uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
                        };
                    }()
                }

            function fontLoaded(){
                console.log('font loaded');
                if (document.getElementsByClassName('site-intro-meta')) {
                    document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
                    document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
                    var postIntroTags = document.getElementsByClassName('post-intro-tags')[0],
                        postIntroMeat = document.getElementsByClassName('post-intro-meta')[0];
                        if (postIntroTags) {
                            postIntroTags.classList.add('post-fade-in');
                        }
                        if (postIntroMeat) {
                            postIntroMeat.classList.add('post-fade-in');
                        }
                    }
                }
                
            console.log("userAgent:" + browser.versions.userAgent);
            // UC不支持跨域，所以直接显示
            if (browser.versions.uc) {
                console.log("UCBrowser");
                fontLoaded();
            } else {
                WebFont.load({
                    custom: {
                        families: ['Oswald-Regular']
                    },
                    loading: function () {  //所有字体开始加载
                        // console.log('loading');
                    },
                    active: function () {  //所有字体已渲染
                        fontLoaded();
                    },
                    inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
                        console.log('inactive: timeout');
                        fontLoaded();
                    },
                    timeout: 7000 // Set the timeout to two seconds
                });
            }
        </script>
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <p><a href="http://blog.csdn.net/u010099080/article/details/53234227" target="_blank" rel="noopener">前面</a> 有篇博文讲了多层感知器，也就是一般的前馈神经网络，文章里使用 CIFAR10 数据集得到的测试准确率是 <strong>46.98%</strong>。今天我们使用更适合处理图像的卷积神经网络来处理相同的数据集 - CIFAR10，来看下准确率能达到多少。</p>
<p>本文代码基于 <a href="https://www.tensorflow.org/tutorials/deep_cnn/" target="_blank" rel="noopener">TensorFlow 的官方文档</a> 做了些许修改，完整代码及结果图片可从 <a href="http://download.csdn.net/download/u010099080/9723302" target="_blank" rel="noopener">这里</a> 下载。</p>
<p><a href="http://blog.csdn.net/u010099080/article/details/62882006" target="_blank" rel="noopener">这篇</a> 文章是对本文的一个升级，增加了 TensorBoard 的实现，可以在浏览器中查看可视化结果，包括准确率、损失、计算图、训练时间和内存信息等。</p>
<a id="more"></a>
<hr>
<h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><p>这里我会列出对本文的更新。</p>
<ul>
<li>2017年3月17日：增加实现 TensorBoard 的文章的链接。</li>
</ul>
<hr>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>关于卷积神经网络（Convolutional Neural Network，以下简称 <strong>CNN</strong>）网上有很多优秀的教程，我在这里也不再重复造轮子，强烈推荐 <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">斯坦福的CS321n</a>，讲的很全面。</p>
<p>还是和以前一样，我在这里简单说下 CNN 的原理。首先来看下一个典型的 CNN - LeNet5 的结构图，</p>
<p><img src="http://img.blog.csdn.net/20161228111539022?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDA5OTA4MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>这个 CNN 是 Yann LeCun 在 1998 年发表的论文 <a href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" target="_blank" rel="noopener">Gradient-Based Learning Applied to Document Recognition</a> 中所提出的，用于字符识别。如上图，模型输入是一个字符图像，然后对输入进行卷积操作（矩阵点乘求和）得到 <code>C1</code> <strong>卷积层</strong>，再进行下采样操作（缩减维度）得到 <code>S2</code> <strong>池化层</strong>或者叫下采样层，然后重复一遍刚才的操作，将二维数据 <em>拉平</em>，连着一个多层的普通神金网络，最终得到输出。训练这个模型的方法还是梯度下降法，或者其变种。</p>
<hr>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>数据集仍然采用 CIFAR10，包含 <strong>60000</strong> 张 <strong>32×32</strong> 的彩色RGB图像，共有 <strong>10</strong> 类，每类有 <strong>6000</strong> 张图像。完整数据集可以从 <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">这里</a> 下载，注意选择 Python 版本，大概是 163 MB。</p>
<p>下载好后解压会看到有 5 个训练文件和 1 个测试文件，还有一个说明文件 <code>batches.meta</code>，这个文件说明了每个数字类别（0-9）具体代表哪些类别。这几个文件都是用 <code>cPickle</code> 打包好的，所以载入数据也要用 <code>cPickle</code> 来载入。注意 <code>Python2</code> 和 <code>Python3</code> 的载入方式稍微有些不同，具体见代码，我使用的是 <code>Python3</code>。</p>
<p>目前在此数据集上做的实验在没有数据增加的情况下最低的错误率是 18%，数据增加的情况下最低的错误率是 11%，都是采用的卷积神经网络（CNN）的结构。</p>
<p>数据集中的图像和分类大致是这样的：</p>
<p><img src="http://i.imgur.com/Rzsw6mo.png" alt=""></p>
<hr>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>由于完整代码较长，这里仅列出关键代码，便于理解整个模型，完整代码可从 <a href="http://download.csdn.net/download/u010099080/9723302" target="_blank" rel="noopener">这里</a> 下载。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模型参数</span></span><br><span class="line">    learning_rate = <span class="number">1e-3</span></span><br><span class="line">    training_iters = <span class="number">500</span></span><br><span class="line">    batch_size = <span class="number">50</span></span><br><span class="line">    display_step = <span class="number">5</span></span><br><span class="line">    n_features = <span class="number">3072</span>  <span class="comment"># 32*32*3</span></span><br><span class="line">    n_classes = <span class="number">10</span></span><br><span class="line">    n_fc1 = <span class="number">384</span></span><br><span class="line">    n_fc2 = <span class="number">192</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建模型</span></span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_features])</span><br><span class="line">    y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_classes])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    w = &#123;</span><br><span class="line">        <span class="string">'conv1'</span>: tf.Variable(tf.truncated_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">64</span>], stddev=<span class="number">5e-2</span>)),</span><br><span class="line">        <span class="string">'conv2'</span>: tf.Variable(tf.truncated_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">64</span>, <span class="number">64</span>], stddev=<span class="number">0.1</span>)),</span><br><span class="line">        <span class="string">'fc1'</span>: tf.Variable(tf.truncated_normal([<span class="number">8</span>*<span class="number">8</span>*<span class="number">64</span>, n_fc1], stddev=<span class="number">0.04</span>)),</span><br><span class="line">        <span class="string">'fc2'</span>: tf.Variable(tf.truncated_normal([n_fc1, n_fc2], stddev=<span class="number">0.1</span>)),</span><br><span class="line">        <span class="string">'fc3'</span>: tf.Variable(tf.truncated_normal([n_fc2, n_classes], stddev=<span class="number">1</span>/<span class="number">192.0</span>))</span><br><span class="line">    &#125;</span><br><span class="line">    b = &#123;</span><br><span class="line">        <span class="string">'conv1'</span>: tf.Variable(tf.constant(<span class="number">0.0</span>, dtype=tf.float32, shape=[<span class="number">64</span>])),</span><br><span class="line">        <span class="string">'conv2'</span>: tf.Variable(tf.constant(<span class="number">0.1</span>, dtype=tf.float32, shape=[<span class="number">64</span>])),</span><br><span class="line">        <span class="string">'fc1'</span>: tf.Variable(tf.constant(<span class="number">0.1</span>, dtype=tf.float32, shape=[n_fc1])),</span><br><span class="line">        <span class="string">'fc2'</span>: tf.Variable(tf.constant(<span class="number">0.1</span>, dtype=tf.float32, shape=[n_fc2])),</span><br><span class="line">        <span class="string">'fc3'</span>: tf.Variable(tf.constant(<span class="number">0.0</span>, dtype=tf.float32, shape=[n_classes]))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    x4d = tf.reshape(x, [<span class="number">-1</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">    <span class="comment"># 卷积层 1</span></span><br><span class="line">    conv1 = tf.nn.conv2d(x4d, w[<span class="string">'conv1'</span>], strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    conv1 = tf.nn.bias_add(conv1, b[<span class="string">'conv1'</span>])</span><br><span class="line">    conv1 = tf.nn.relu(conv1)</span><br><span class="line">    <span class="comment"># 池化层 1</span></span><br><span class="line">    pool1 = tf.nn.max_pool(conv1, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    <span class="comment"># LRN层，Local Response Normalization</span></span><br><span class="line">    norm1 = tf.nn.lrn(pool1, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span>/<span class="number">9.0</span>, beta=<span class="number">0.75</span>)</span><br><span class="line">    <span class="comment"># 卷积层 2</span></span><br><span class="line">    conv2 = tf.nn.conv2d(norm1, w[<span class="string">'conv2'</span>], strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    conv2 = tf.nn.bias_add(conv2, b[<span class="string">'conv2'</span>])</span><br><span class="line">    conv2 = tf.nn.relu(conv2)</span><br><span class="line">    <span class="comment"># LRN层，Local Response Normalization</span></span><br><span class="line">    norm2 = tf.nn.lrn(conv2, <span class="number">4</span>, bias=<span class="number">1.0</span>, alpha=<span class="number">0.001</span>/<span class="number">9.0</span>, beta=<span class="number">0.75</span>)</span><br><span class="line">    <span class="comment"># 池化层 2</span></span><br><span class="line">    pool2 = tf.nn.max_pool(norm2, ksize=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">    reshape = tf.reshape(pool2, [<span class="number">-1</span>, <span class="number">8</span>*<span class="number">8</span>*<span class="number">64</span>])</span><br><span class="line">    dim = reshape.get_shape()[<span class="number">1</span>].value</span><br><span class="line">    fc1 = tf.add(tf.matmul(reshape, w[<span class="string">'fc1'</span>]), b[<span class="string">'fc1'</span>])</span><br><span class="line">    fc1 = tf.nn.relu(fc1)</span><br><span class="line">    <span class="comment"># 全连接层 2</span></span><br><span class="line">    fc2 = tf.add(tf.matmul(fc1, w[<span class="string">'fc2'</span>]), b[<span class="string">'fc2'</span>])</span><br><span class="line">    fc2 = tf.nn.relu(fc2)</span><br><span class="line">    <span class="comment"># 全连接层 3, 即分类层</span></span><br><span class="line">    fc3 = tf.add(tf.matmul(fc2, w[<span class="string">'fc3'</span>]), b[<span class="string">'fc3'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义损失</span></span><br><span class="line">    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(fc3, y))</span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line">    <span class="comment"># 评估模型</span></span><br><span class="line">    correct_pred = tf.equal(tf.argmax(fc3, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    c = []</span><br><span class="line">    total_batch = int(X_train.shape[<span class="number">0</span>] / batch_size)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(training_iters):</span><br><span class="line">        avg_cost = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_x = X_train[batch*batch_size : (batch+<span class="number">1</span>)*batch_size, :]</span><br><span class="line">            batch_y = y_train[batch*batch_size : (batch+<span class="number">1</span>)*batch_size, :]</span><br><span class="line">            _, co = sess.run([optimizer, cost], feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">            avg_cost += co</span><br><span class="line">    </span><br><span class="line">        c.append(avg_cost)</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Iter "</span> + str(i+<span class="number">1</span>) + <span class="string">", Training Loss= "</span> + <span class="string">"&#123;:.6f&#125;"</span>.format(avg_cost))</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Test</span></span><br><span class="line">    test_acc = sess.run(accuracy, feed_dict=&#123;x: X_test, y: y_test&#125;)</span><br><span class="line">    print(<span class="string">"Testing Accuracy:"</span>, test_acc)</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p><img src="http://img.blog.csdn.net/20161228121428562?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDA5OTA4MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>其中的缩写仍然遵照我以前博文的习惯：</p>
<ul>
<li>lr：learning rate，学习率</li>
<li>ti：training iters，训练迭代次数</li>
<li>bs：batch size，batch大小</li>
<li>acc：测试准确率</li>
</ul>
<p>每次结果都会不一样，上图是最好的结果的时候，其他结果图的下载链接和上面一样，测试准确率大约为 60%，其实这个准确率并不高，和 <a href="https://www.tensorflow.org/tutorials/deep_cnn/" target="_blank" rel="noopener">TensorFlow 的官方文档</a> 所得到的 86% 还差一段距离，和官方文档的差距在于我并没有对数据进行更多的预处理，例如图像裁剪到 24×24 的尺寸、标准化、随机左右翻转图像或者随机改变图像亮度和对比度以扩大数据集等等，等有时间再进行进一步的实验，与本次实验进行对比。</p>
<p><em>在其他条件一样的情况下，本次实验得到的准确率可能并不是最高的，鉴于机器太垃圾，运行一次实验需要两三天，未能进行更多的测试。</em></p>
<hr>
<h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1>
    </article>
    <!-- 前后页  -->
    <ul class="post-pager">
        
            <li class="next">
                <a href= "/2017/02/16/tensorflow-1.0/" title= TensorFlow 1.0 发布 >
                    <span>Next Post</span>
                    <span>TensorFlow 1.0 发布</span>
                </a>
            </li>
        
        
            <li class="previous">
                <a href= "/2016/12/10/tensorboard-mnist-pca/" title= 在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集 >
                    <span>Previous Post</span>
                    <span>在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集</span>
                </a>
            </li>
        
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    <div id="disqus_thread"></div>
    <script>
        /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
        
        var disqus_config = function () {
        this.page.url = "https://secsilm.github.io/2016/12/28/tensorflow-cnn-no-tensorboard/";  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        
        (function () { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://secsilm.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();

    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

    
    <!--PC版-->

    <!--PC版-->


    
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:secsilm@outlook.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/secsilm" class="iconfont-archer github" target="_blank" title="github"></a>
            
        
    
        
            
                <a href="https://twitter.com/SilverSecondMan" class="iconfont-archer twitter" target="_blank" title="twitter"></a>
            
        
    
        
            
                <a href="https://www.instagram.com/secsilm/" class="iconfont-archer instagram" target="_blank" title="instagram"></a>
            
        
    
        
            
                <a href="/atom.xml" class="iconfont-archer rss" target="_blank" title="rss"></a>
            
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">Theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
        <span id="busuanzi_container_site_pv">Welcome, No. <span id="busuanzi_value_site_pv"></span> visitor.
        </span>
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper">
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#更新"><span class="toc-number">1.</span> <span class="toc-text">更新</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#原理"><span class="toc-number">2.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据集"><span class="toc-number">3.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#代码"><span class="toc-number">4.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#结果"><span class="toc-number">5.</span> <span class="toc-text">结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#END"><span class="toc-number">6.</span> <span class="toc-text">END</span></a></li></ol>
    </div>
    
    <div class="back-top">&#xe639;</div>
    <div class="sidebar">
    <div class="sidebar-header sidebar-header-show-archive">
        <div class="sidebar-category">
            <span class="sidebar-archive-link"><span class="iconfont-archer">&#xe67d;</span>Archive</span>
            <span class="sidebar-tags-link"><span class="iconfont-archer">&#xe610;</span>Tag</span>
        </div>
    </div>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-archive">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-archive"> Total : 44 </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2017 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/30</span><a class="archive-post-title" href= "/2017/12/30/google-sitemap/" >Google sitemap 不允许的网址的解决办法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/29</span><a class="archive-post-title" href= "/2017/12/29/understanding-lstms/" >理解 LSTM 网络</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/25</span><a class="archive-post-title" href= "/2017/12/25/export-csdn-blogs-to-md/" >批量导出 CSDN 博客为 Markdown 文件</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/22</span><a class="archive-post-title" href= "/2017/12/22/understanding-estimators-datasets/" >理解 Estimators 和 Datasets</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/26</span><a class="archive-post-title" href= "/2017/10/26/windows10-dark-theme/" >Windows 10 资源管理器黑色风格</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/08</span><a class="archive-post-title" href= "/2017/10/08/gradient-descent-methods/" >梯度下降优化算法概述</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/30</span><a class="archive-post-title" href= "/2017/08/30/ensemble-methods/" >使用集成学习提升机器学习算法性能</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/20</span><a class="archive-post-title" href= "/2017/08/20/understanding-tensorboard/" >理解 TensorBoard</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/17</span><a class="archive-post-title" href= "/2017/06/17/numpy-shuffle-permutation/" >Numpy 中的 shuffle VS permutation</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/02</span><a class="archive-post-title" href= "/2017/06/02/tensorflow-DNNRegressor/" >TensorFlow DNNRegressor 的简单使用</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/18</span><a class="archive-post-title" href= "/2017/05/18/installing-xgboost/" >XGBoost 在 Windows 10 和 Ubuntu 上的安装</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/22</span><a class="archive-post-title" href= "/2017/04/22/python-fire/" >Python 自动生成命令行工具 - fire 简介</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/29</span><a class="archive-post-title" href= "/2017/03/29/understanding-svd/" >奇异值分解 SVD 的数学解释</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/25</span><a class="archive-post-title" href= "/2017/03/25/python-string-count/" >使用 Python 统计字符串中英文、空格、数字、标点个数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/17</span><a class="archive-post-title" href= "/2017/03/17/tensorflow-cnn-tensorboard/" >TensorFlow 中的卷积神经网络 CNN - TensorBoard 版</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/15</span><a class="archive-post-title" href= "/2017/03/15/using-tree/" >使用 tree 命令格式化输出目录结构</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/11</span><a class="archive-post-title" href= "/2017/03/11/vscode-pdf-error/" >VSCode Markdown PDF 导出成PDF报 phantomjs binary does not exist 错误的解决办法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2017/03/01/numpy-copy/" >Numpy 中的 copy 问题详解</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/26</span><a class="archive-post-title" href= "/2017/02/26/tensorflow-cudnn-version/" >Check failed stream->parent()->GetConvolveAlgorithms(&algorithms)解决办法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/16</span><a class="archive-post-title" href= "/2017/02/16/tensorflow-1.0/" >TensorFlow 1.0 发布</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2016 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/28</span><a class="archive-post-title" href= "/2016/12/28/tensorflow-cnn-no-tensorboard/" >TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/10</span><a class="archive-post-title" href= "/2016/12/10/tensorboard-mnist-pca/" >在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/01</span><a class="archive-post-title" href= "/2016/12/01/installing-tensorflow/" >Windows10 64 位下安装 TensorFlow - 官方原生支持</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/30</span><a class="archive-post-title" href= "/2016/11/30/numpy-array-memory/" >小谈 Numpy 数组占用内存空间问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/19</span><a class="archive-post-title" href= "/2016/11/19/tensorflow-mlp/" >TensorFlow 中的多层感知器（MLP）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/06</span><a class="archive-post-title" href= "/2016/11/06/tensorflow-logistic-regression/" >TensorFlow 中的 Logistic Regression</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/03</span><a class="archive-post-title" href= "/2016/11/03/pandas-apply/" >Pandas 中的 apply 函数使用示例</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/29</span><a class="archive-post-title" href= "/2016/10/29/tensorflow-hyperparams/" >学习率、迭代次数和初始化方式对模型准确率的影响</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/26</span><a class="archive-post-title" href= "/2016/10/26/sklearn-logistics-regression-parameters/" >sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/24</span><a class="archive-post-title" href= "/2016/10/24/plt-save/" >解决使用 plt.savefig 保存图片时一片空白</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/22</span><a class="archive-post-title" href= "/2016/10/22/tensorflow-linear-regression/" >TensorFlow 中的线性回归</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/16</span><a class="archive-post-title" href= "/2016/10/16/python-email/" >用 Python 发电子邮件</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/27</span><a class="archive-post-title" href= "/2016/08/27/ubuntu-installing-tensorflow/" >Ubuntu 14.04 64 位安装 Google 的 TensorFlow</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/22</span><a class="archive-post-title" href= "/2016/08/22/ubuntu-update-issue/" >Ubuntu 14.04 64 位系统更新重启后无法进入系统，光标不停闪烁</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/27</span><a class="archive-post-title" href= "/2016/06/27/python-strptime/" >Python 中 strptime 的简单使用</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/03</span><a class="archive-post-title" href= "/2016/04/03/python-numpy/" >Python NumPy 基础</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/24</span><a class="archive-post-title" href= "/2016/03/24/ubuntu-gedit-change-theme/" >Ubuntu14.04 gnome3 下 gedit 首选项消失时如何修改 gedit 主题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/18</span><a class="archive-post-title" href= "/2016/01/18/matlab-plot-parallelepiped/" >MATLAB绘制平行六面体</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/11</span><a class="archive-post-title" href= "/2016/01/11/matlab-mat2cell/" >MATLAB 矩阵分块函数 mat2cell 及 cellfun 函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/11</span><a class="archive-post-title" href= "/2016/01/11/machine-learning-book-note/" >《机器学习》学习笔记1——绪论 机器学习概述</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2015 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/21</span><a class="archive-post-title" href= "/2015/12/21/matlab-fitlm/" >使用 MATLAB 的 fitlm 函数进行线性回归</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/19</span><a class="archive-post-title" href= "/2015/11/19/matlab-rename-files/" >MATLAB 批量文件重命名（详细解释）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/05</span><a class="archive-post-title" href= "/2015/11/05/matlab-callback/" >MATLAB GUI 中 Edit Text 的 Callback 函数何时执行</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2015/09/22/matlab-move-files/" >用 MATLAB 将多个文件夹内的某些文件汇总到另一个文件夹</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name"><a href= "#">Machine Learning</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Translation</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">hexo</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Python</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">TensorFlow</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Data Science</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">MATLAB</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">sklearn</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Ubuntu</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">IDE</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Windows</a></span>
    
    </div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: false
    tags: true</pre>
    </div> 
    <div class="sidebar-tag-list"></div>
</div>
    </div>
</div> 
    <script>
    var jsInfo = {
        root: '/'
    }
</script>
    <!-- 不蒜子  -->
    
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ统计  -->
    
    </div>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>


