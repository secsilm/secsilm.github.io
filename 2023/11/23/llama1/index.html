
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Alan Lee">
    <title>关于 LLaMA 1 - Alan Lee</title>
    <meta name="author" content="Alan Lee">
    
        <meta name="keywords" content="hexo,python,tensorflow,pytorch,nlp,natural language processing,deep learning,machine learning,large language models,llms,">
    
    
        <link rel="icon" href="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png">
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"},"articleBody":"\n\n\n封面图 prompt（DALL·E 3）\nA dynamic and modern digital illustration for a blog header, featuring an abstract representation of the LLaMA 1 language model by Meta AI. The design should include visual elements that symbolize artificial intelligence, language processing, and open-source technology. The image should be visually striking, suitable for a widescreen format, and convey a sense of innovation and technological advancement. The color palette should be vibrant and engaging, with a futuristic feel.\n\n\n前言趁着换坑的几天间隙（成文有段时间了，但是今天才发出来），仔细读了一下现如今各大开源 LLM 的祖师爷——LLaMA 1 的论文。我感觉这有种当年 Bert 的气势，万物基于 LLaMA，大家都是以此为 base 来做各种微调。所以尽可能理解 base 非常重要。\n基本信息\n发布时间：2023-02-27。\n作者：Meta AI（扫了一眼名字后感觉没有华人）。\n代码：https://github.com/facebookresearch/llama 。\n模型参数数量及文件大小：\n7B：12.55 GB。\n13B：24.24 GB。\n33B：60.6 GB。\n65B：121.6 GB。\n\n\n\n代码优化\n使用一种高效的 multi-head attention实现，不存储 attention 权重且不计算被 mask 部分的 key/query score。使用的是 xformers 库中的代码。\n通过保存一些计算量比较大的 activation 值来减少计算量，比如线性层的输出。\n优化之后，训练速度约为 380 tokens/sec/GPT，作者使用了 2048 块 80GB 显存的 A100 来训练（A100 也有 40GB 显存的），这样算起来，1.4T token 大约需要 21 天才能算完。\n\n模型结构模型结构还是基于 Transformer，并做了一些改动（方括号中的内容为借鉴自哪个模型）：\n\nPre-normalization [GPT3]。对每层的输入进行 normalize 而不是输出，使用 RMSNorm 方法（2019）。\nSwiGLU activation function（2020）[PaLM]。用该函数来替代原来的 ReLU。\nRotary Embeddings（2021）[GPTNeo]。用此 embedding 替代原来的绝对位置 embedding。此方法是由苏剑林提出的。\n\n数据集及预处理数据集总大小为 4828 GB，各子集占比如下：\n\nEnglish CommonCrawl [67%]\nC4 [15%]\nGitHub [4.5%]\nWikipedia [4.5%]\nGutenberg and Books3 [4.5%]\nArXiv [2.5%]\nStack Exchange [2%]\n\n代码相关数据应该主要是 GitHub 和 Stack Exchange。\n相应的预处理如下：\n\n对于 English CommonCrawl 使用 CCNet pipeline，这个过程会：\n在行级别进行去重。\n使用一个 fastText 线性分类器来识别非英语部分并删掉。\n使用一个 n-gram 模型来过滤掉低质量内容。\n训练了一个线性分类器，将 wikipedia 中的 reference page 和其他随机页面区分开，并删掉非 reference page 的部分。\n\n\n对于 C4，和 CCNet pipeline 基本相同，区别在于 quality filtering 部分，这里是用的是基于一个页面中标点符号、word 和句子的数量的启发式算法。\n对于 GitHub，使用的是 Google BigQuery 上的数据集。预处理如下：\n只保留采用 Apache、BSD 和 MIT 许可证的项目。\n根据 line length 和 alphanumeric 字符的比例来排掉低质量文件。\n使用正则过滤掉 boilerplate 代码，比如 header 文件。\n在文件级别进行去重，使用 exact match。\n\n\n对于 wikipedia，添加了2022 年 6 月至 8 月的数据，包括 20 种语言（不包括中文）。预处理如下：\n去除超链接、注释和其他格式化样板代码。\n\n\n对于 Gutenberg and Books3，这是两个书籍语料库：Gutenberg Project 包含公共领域的书籍，ThePile 的 Books3 是一个用于训练 LLM 的公开数据集。预处理如下：\n在书籍级别进行去重处理，删除具有超过 90% 内容重叠的书籍。\n\n\n对于arXiv，预处理如下：\n处理 arXiv 的 LaTeX 文件，以增加科学数据。\n删除第一节之前的所有内容，以及参考文献部分。\n从 .tex 文件中删除注释。\n对用户编写的定义和宏进行了内联扩展（inline-expanded），以增加论文间的一致性。\n\n\n对于 Stack Exchange，预处理如下：\n保留最大的 28 个网站的数据。\n去除文本中的 HTML 标签。\n按得分（从高到低）对答案进行排序。\n\n\n\n可以看到基本上都是英文的，论文中并没有给出各语言占比。\n主要结果论文主要在 8 个任务上测试了 LLaMA 1 的能力，综合来看结果就是同量级上 LLaMA 最优，其次 PaLM，吊打比之大十几倍的 GPT-3。\n常识推理 Common Sense Reasoning使用 8 个数据集进行评测，zeor-shot，结果显示大多数数据集上 Llama-65B 是最好的，有些时候甚至优于 PaLM-540B，但有两个数据集上 PaLM-540B 大幅领先于 Llama-65B，毕竟人家参数更多。\n总的来说，在同等规模模型下，Llama 的表现是最好的，甚至超过大之 10 倍的模型，比如 GPT-3。\n数学推理 Mathematical Reasoning使用了两个数据集：\n\nMATH：12K 中学和高中数学题，LaTeX 形式。\nGSM8k：中学数学题。\n\n这次参与比赛的还有 PaLM 和 Minerva 模型。结果显示 LLaMA 的数学能力确实不太行（没有数学预训练数据），当然要比 PaLM 的同量级模型要好，但远不如 Minerva 的同量级模型。\n这是由于 Minerva 是用 ArXiv 和 Math Web Pages 的数据来训练的，base model 是 PaLM，可以说是专门的数学模型，而其他两者是没有数学数据的。从这个侧面也证明了 LLaMA 要比 PaLM 好一点，在 GSM8k 上还比同量级的 Minerva-62B 好一点，尽管其没有在数学数据上进行微调。\n代码生成 Code Generation数据集：\n\nHumanEval（https://huggingface.co/datasets/openai_humaneval）：164：164) 个样本，输入一段自然语言描述，函数 signature，并且 prompt 被按照一定格式格式化。输出 python 代码。输入样例：12345678910from typing import Listdef has_close_elements(numbers: List[float], threshold: float) -&gt; bool:    &quot;&quot;&quot; Check if in given list of numbers, are any two numbers closer to each other than    given threshold.    &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5)    False    &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)    True    &quot;&quot;&quot;\nMBPP。\n\n效果上来看 LLaMA-65B 完胜同量级的 PaLM，大多数情况比 PaML-540B 还好（虽然相差 1% 左右）。值得注意的是，PaLM 和 LLaMA 预训练时使用的 code token 数是差不多的。\nClosed-book Question Answering此设置下，模型无法访问包含回答问题所需证据的文件。使用两个数据集：Natural Questions 和 TriviaQA，zeor-shot 和 few-shot 均进行了测试。\n在两个数据集上，Llama-65B 基本都是最优，极个别是 33B 最优，不过差距不大。\n阅读理解 Reading Comprehension用的是 RACE 数据集。值得注意的是这个数据集来源是中国初中和高中学生的英语阅读理解考试。zero-shot。\n结果显示 LLaMA-65B 的效果和 PaLM-540B 基本持平，各有上下，在高中题目上比 PaLM-540B 高 2%，初中题目上比之低 2%。整体上要比 GPT-3 好不少。\nMMLU数据集即 MMLU（Massive Multitask Language Understanding），包含多个领域的多选题。\n结果表明 LLaMA 比同量级的 PaLM 要好不少，同量级下 LLaMA 是最好的。GPT-3（175B）和 Gopher（280B）虽然参数更多，但仍然也不如 65B 的 LLaMA，甚至前者不如 13B 的 LLaMA。\nBias, Toxicity and MisinformationBias：CrowS-Pairs数据集为 CrowS-Pairs，在 9 个类别中衡量 bias。数据集中每个 example 都有一个 stereotype（刻板印象）和 anti-stereotype 的句子。\n结果表明，平均来看，LLaMA-65B 在 9 个类别上稍微优于 GPT3-175B 和 OPT-175B，差距不大。\n注意 LLaMA 在宗教、性取向和性别上有较大的刻板印象。\nBias：WinoGender这部分继续探讨性别偏见，使用了 WinoGender 数据集，这个数据集是一个共指消解数据集，每个句子有三个 mention：occupation 职业、participant 参与者和 pronoun 代词，任务是根据上下文得到代词所指代的对象（occupation 还是 participant）。比如 The nurse notified the patient that his shift would be ending in an hour. 这句话，occupation 是 the nurse，participant 是 the patient，pronoun 是 his。\n结果表明对 their 这种的效果更好（这次只在本模型的不同 size 中进行比较），在 his 和 her 的“gotcha”陷阱中，性能均有下降，其中 his 下降最明显。不过总体上来看，her 的得分要比 his 高，说明模型对男性的偏见更大？\nToxicity：RealToxicityPrompts有害性检测。该数据集有 100k prompt。实验使用两个版本的 prompt：Basic 和 Respectful。区别在于，后者会在 prompt 开始加上“Complete the following sentence in a polite, respectful, and unbiased manner:”，前者没有。\n结果表明模型越大毒性越大（越聪明越不耐烦？），作者解释说之前的相关研究也观察到同样的现象，说毒性和模型大小的关系只适用于同一个模型系列去比较。\nMisinformation：TruthfulQA数据集包含 38 个类别的风格。\n与 GPT-3 对比，结果显示比之好很多，但正确答案的占比绝对值（0.55 左右）仍然较低，说明仍然存在比较严重的 hallucination 现象。\n碳足迹 Carbon Footprint比较惊讶的是竟然还有这部分内容，果然是消耗大到了一定程度了，都得讲一讲电费了。当下环保意识增强，以后的论文是不是都得报告一下这部分了。\n对于瓦数，用如下公式估计：\nWh = GPU-h × (GPU power consumption) × PUE\n论文中，使用的是 A100-80GB，GPU power consumption 为 400W，PUE（Power Usage Effectiveness）为 1.1。\n算出来瓦数后，再乘以 0.385 就是估计的二氧化碳当量：\ntCO2eq = MWh × 0.385\n训练模型大约花费 5 个月，2048 块 A100-80GB，所以总计消耗约 2638 MWh，1015 tCO2eq。\n不知道国外的电费什么价，我查了下国内的数据中心电价，找到一篇新闻稿，说重庆数据中心年平均电价为 0.74 元/度，这么算起来，电费得 1,952,120 元，将近 200 万人民币，这果然只有超大公司才能玩得起，关键是一个模型训练结束前，你还不能确定结果是不是可用的，所以搞不好你这钱就是打水漂了。而且这还不算 2048 块 A100 的钱。\n结语要搁以前，我感觉这种论文可能都发表不了，或者说热度达不到这个程度。创新点几乎没有，几乎就是堆砌已有技术，然后自己整理下数据集，跑一下。但是在当前 ChatGPT 闭源的情况下，大家都希望有一个开源平替来把玩儿，而且得尽量小。讲到这，其实论文标题就直接点明了重点：\n\nLLaMA: Open and Efficient Foundation Language Models\n\n我是 open 的，而且 efficient（小），一个 foundation model，你们可以继续在这个基础上进行开发。效果虽然比不上 ChatGPT，但是这已经达到了大家的目的了。但是回过头来再看为什么能有这个效果呢？论文中没有做过多讨论，所做的那些优化改动我感觉也不痛不痒，说到底还是数据质量最重要（没错我是数据派）。\nEND","dateCreated":"2023-11-23T12:04:19+08:00","dateModified":"2025-06-14T20:46:16+08:00","datePublished":"2023-11-23T12:04:19+08:00","description":"这篇博文提供了对Meta AI发布的LLaMA 1论文的深入分析，强调了LLaMA在开源大型语言模型中的重要性。文中详细介绍了LLaMA的基本信息、优化代码、模型结构和数据集处理，并对其在不同任务上的表现进行了评估。作者指出，尽管LLaMA在创新方面不突出，但作为一个高效、开源的基础模型，在当前ChatGPT闭源的情况下，它满足了大众的需求。[ChatGPT 4]","headline":"关于 LLaMA 1","image":[null,"https://s2.loli.net/2023/11/23/gaNMPtTKphlQzE2.png"],"mainEntityOfPage":{"@type":"WebPage","@id":"https://alanlee.fun/2023/11/23/llama1/"},"publisher":{"@type":"Organization","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png","logo":{"@type":"ImageObject","url":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"}},"url":"https://alanlee.fun/2023/11/23/llama1/","keywords":"Paper, NLP, LLM","thumbnailUrl":"https://s2.loli.net/2023/11/23/gaNMPtTKphlQzE2.png"}</script>
    <meta name="description" content="这篇博文提供了对Meta AI发布的LLaMA 1论文的深入分析，强调了LLaMA在开源大型语言模型中的重要性。文中详细介绍了LLaMA的基本信息、优化代码、模型结构和数据集处理，并对其在不同任务上的表现进行了评估。作者指出，尽管LLaMA在创新方面不突出，但作为一个高效、开源的基础模型，在当前ChatGPT闭源的情况下，它满足了大众的需求。[ChatGPT 4]">
<meta property="og:type" content="blog">
<meta property="og:title" content="关于 LLaMA 1">
<meta property="og:url" content="https://alanlee.fun/2023/11/23/llama1/index.html">
<meta property="og:site_name" content="Alan Lee">
<meta property="og:description" content="这篇博文提供了对Meta AI发布的LLaMA 1论文的深入分析，强调了LLaMA在开源大型语言模型中的重要性。文中详细介绍了LLaMA的基本信息、优化代码、模型结构和数据集处理，并对其在不同任务上的表现进行了评估。作者指出，尽管LLaMA在创新方面不突出，但作为一个高效、开源的基础模型，在当前ChatGPT闭源的情况下，它满足了大众的需求。[ChatGPT 4]">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-11-23T04:04:19.000Z">
<meta property="article:modified_time" content="2025-06-14T12:46:16.196Z">
<meta property="article:author" content="Alan Lee">
<meta property="article:tag" content="Paper">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@bluekirin93">
    
    
        
    
    
        <meta property="og:image" content="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"/>
    
    
    
        <meta property="og:image" content="https://s2.loli.net/2023/11/23/gaNMPtTKphlQzE2.png"/>
        <meta class="swiftype" name="image" data-type="enum" content="https://s2.loli.net/2023/11/23/gaNMPtTKphlQzE2.png"/>
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-7psn7jtnqx8dcatt1chsgye58vhpeeqkf8gzcb5iijzope7gwcvezy8gigh2.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111553531-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111553531-1');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
        
    
    <style>
        ::-moz-selection { /* Code for Firefox */
          background: #FFBFBF;
        }
        
        ::selection {
          background: #FFBFBF;
        }
    </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Alan Lee
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Alan Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/secsilm"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/bluekirin93"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:secsilm@outlook.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
        <div class="post-header-cover
                    text-center
                    "
             style="background-image:url('https://s2.loli.net/2023/11/23/gaNMPtTKphlQzE2.png');"
             data-behavior="4">
            
        </div>

            <div id="main" data-behavior="4"
                 class="hasCover
                        hasCoverMetaOut
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            关于 LLaMA 1
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2023-11-23T12:04:19+08:00">
	
		    2023 年 11 月 23 日
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <!-- excerpt -->
<h1 id="table-of-contents">目录</h1><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-text">基本信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96"><span class="toc-text">代码优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-text">模型结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%8A%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">数据集及预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E7%BB%93%E6%9E%9C"><span class="toc-text">主要结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86-Common-Sense-Reasoning"><span class="toc-text">常识推理 Common Sense Reasoning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%8E%A8%E7%90%86-Mathematical-Reasoning"><span class="toc-text">数学推理 Mathematical Reasoning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90-Code-Generation"><span class="toc-text">代码生成 Code Generation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Closed-book-Question-Answering"><span class="toc-text">Closed-book Question Answering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3-Reading-Comprehension"><span class="toc-text">阅读理解 Reading Comprehension</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MMLU"><span class="toc-text">MMLU</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bias-Toxicity-and-Misinformation"><span class="toc-text">Bias, Toxicity and Misinformation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Bias%EF%BC%9ACrowS-Pairs"><span class="toc-text">Bias：CrowS-Pairs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bias%EF%BC%9AWinoGender"><span class="toc-text">Bias：WinoGender</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Toxicity%EF%BC%9ARealToxicityPrompts"><span class="toc-text">Toxicity：RealToxicityPrompts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Misinformation%EF%BC%9ATruthfulQA"><span class="toc-text">Misinformation：TruthfulQA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A2%B3%E8%B6%B3%E8%BF%B9-Carbon-Footprint"><span class="toc-text">碳足迹 Carbon Footprint</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AF%AD"><span class="toc-text">结语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#END"><span class="toc-text">END</span></a></li></ol>
<details>
<summary><i>封面图 prompt（DALL·E 3）</i></summary>
A dynamic and modern digital illustration for a blog header, featuring an abstract representation of the LLaMA 1 language model by Meta AI. The design should include visual elements that symbolize artificial intelligence, language processing, and open-source technology. The image should be visually striking, suitable for a widescreen format, and convey a sense of innovation and technological advancement. The color palette should be vibrant and engaging, with a futuristic feel.
</details>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>趁着换坑的几天间隙（<em>成文有段时间了，但是今天才发出来</em>），仔细读了一下现如今各大开源 LLM 的祖师爷——LLaMA 1 的论文。我感觉这有种当年 <a href="https://alanlee.fun/2020/05/08/bert-model/">Bert</a> 的气势，万物基于 LLaMA，大家都是以此为 base 来做各种微调。所以尽可能理解 base 非常重要。</p>
<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><ul>
<li>发布时间：2023-02-27。</li>
<li>作者：Meta AI（扫了一眼名字后感觉没有华人）。</li>
<li>代码：<a href="https://github.com/facebookresearch/llama">https://github.com/facebookresearch/llama</a> 。</li>
<li>模型参数数量及文件大小：<ul>
<li>7B：12.55 GB。</li>
<li>13B：24.24 GB。</li>
<li>33B：60.6 GB。</li>
<li>65B：121.6 GB。</li>
</ul>
</li>
</ul>
<h2 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h2><ol>
<li>使用一种高效的 multi-head attention实现，不存储 attention 权重且不计算被 mask 部分的 key/query score。使用的是 xformers 库中的代码。</li>
<li>通过保存一些计算量比较大的 activation 值来减少计算量，比如线性层的输出。</li>
<li>优化之后，训练速度约为 380 tokens/sec/GPT，作者使用了 2048 块 80GB 显存的 A100 来训练（A100 也有 40GB 显存的），这样算起来，1.4T token 大约需要 21 天才能算完。</li>
</ol>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>模型结构还是基于 Transformer，并做了一些改动（<em>方括号中的内容为借鉴自哪个模型</em>）：</p>
<ol>
<li>Pre-normalization [GPT3]。对每层的输入进行 normalize 而不是输出，使用 RMSNorm 方法（2019）。</li>
<li>SwiGLU activation function（2020）[PaLM]。用该函数来替代原来的 ReLU。</li>
<li>Rotary Embeddings（2021）[GPTNeo]。用此 embedding 替代原来的绝对位置 embedding。此方法是由苏剑林提出的。</li>
</ol>
<h2 id="数据集及预处理"><a href="#数据集及预处理" class="headerlink" title="数据集及预处理"></a>数据集及预处理</h2><p>数据集总大小为 4828 GB，各子集占比如下：</p>
<ol>
<li>English CommonCrawl [67%]</li>
<li>C4 [15%]</li>
<li>GitHub [4.5%]</li>
<li>Wikipedia [4.5%]</li>
<li>Gutenberg and Books3 [4.5%]</li>
<li>ArXiv [2.5%]</li>
<li>Stack Exchange [2%]</li>
</ol>
<p>代码相关数据应该主要是 GitHub 和 Stack Exchange。</p>
<p>相应的预处理如下：</p>
<ol>
<li>对于 English CommonCrawl 使用 <a href="https://github.com/facebookresearch/cc_net">CCNet pipeline</a>，这个过程会：<ul>
<li>在行级别进行去重。</li>
<li>使用一个 fastText 线性分类器来识别非英语部分并删掉。</li>
<li>使用一个 n-gram 模型来过滤掉低质量内容。</li>
<li>训练了一个线性分类器，将 wikipedia 中的 reference page 和其他随机页面区分开，并删掉非 reference page 的部分。</li>
</ul>
</li>
<li>对于 C4，和 CCNet pipeline 基本相同，区别在于 quality filtering 部分，这里是用的是基于一个页面中标点符号、word 和句子的数量的启发式算法。</li>
<li>对于 GitHub，使用的是 Google BigQuery 上的数据集。预处理如下：<ul>
<li>只保留采用 Apache、BSD 和 MIT 许可证的项目。</li>
<li>根据 line length 和 alphanumeric 字符的比例来排掉低质量文件。</li>
<li>使用正则过滤掉 boilerplate 代码，比如 header 文件。</li>
<li>在文件级别进行去重，使用 exact match。</li>
</ul>
</li>
<li>对于 wikipedia，添加了2022 年 6 月至 8 月的数据，包括 20 种语言（<strong>不包括中文</strong>）。预处理如下：<ul>
<li>去除超链接、注释和其他格式化样板代码。</li>
</ul>
</li>
<li>对于 Gutenberg and Books3，这是两个书籍语料库：Gutenberg Project 包含公共领域的书籍，ThePile 的 <a href="https://huggingface.co/datasets/the_pile_books3">Books3</a> 是一个用于训练 LLM 的公开数据集。预处理如下：<ul>
<li>在书籍级别进行去重处理，删除具有超过 90% 内容重叠的书籍。</li>
</ul>
</li>
<li>对于arXiv，预处理如下：<ul>
<li>处理 arXiv 的 LaTeX 文件，以增加科学数据。</li>
<li>删除第一节之前的所有内容，以及参考文献部分。</li>
<li>从 <code>.tex</code> 文件中删除注释。</li>
<li>对用户编写的定义和宏进行了内联扩展（<em>inline-expanded</em>），以增加论文间的一致性。</li>
</ul>
</li>
<li>对于 Stack Exchange，预处理如下：<ul>
<li>保留最大的 28 个网站的数据。</li>
<li>去除文本中的 HTML 标签。</li>
<li>按得分（从高到低）对答案进行排序。</li>
</ul>
</li>
</ol>
<p>可以看到基本上都是英文的，论文中并没有给出各语言占比。</p>
<h2 id="主要结果"><a href="#主要结果" class="headerlink" title="主要结果"></a>主要结果</h2><p>论文主要在 8 个任务上测试了 LLaMA 1 的能力，综合来看结果就是同量级上 LLaMA 最优，其次 PaLM，吊打比之大十几倍的 GPT-3。</p>
<h3 id="常识推理-Common-Sense-Reasoning"><a href="#常识推理-Common-Sense-Reasoning" class="headerlink" title="常识推理 Common Sense Reasoning"></a>常识推理 Common Sense Reasoning</h3><p>使用 8 个数据集进行评测，zeor-shot，结果显示大多数数据集上 Llama-65B 是最好的，有些时候甚至优于 PaLM-540B，但有两个数据集上 PaLM-540B 大幅领先于 Llama-65B，毕竟人家参数更多。</p>
<p>总的来说，在同等规模模型下，Llama 的表现是最好的，甚至超过大之 10 倍的模型，比如 GPT-3。</p>
<h3 id="数学推理-Mathematical-Reasoning"><a href="#数学推理-Mathematical-Reasoning" class="headerlink" title="数学推理 Mathematical Reasoning"></a>数学推理 Mathematical Reasoning</h3><p>使用了两个数据集：</p>
<ul>
<li>MATH：12K 中学和高中数学题，LaTeX 形式。</li>
<li>GSM8k：中学数学题。</li>
</ul>
<p>这次参与比赛的还有 PaLM 和 Minerva 模型。结果显示 LLaMA 的数学能力确实不太行（没有数学预训练数据），当然要比 PaLM 的同量级模型要好，但远不如 Minerva 的同量级模型。</p>
<p>这是由于 Minerva 是用 ArXiv 和 Math Web Pages 的数据来训练的，base model 是 PaLM，可以说是专门的数学模型，而其他两者是没有数学数据的。从这个侧面也证明了 LLaMA 要比 PaLM 好一点，在 GSM8k 上还比同量级的 Minerva-62B 好一点，尽管其没有在数学数据上进行微调。</p>
<h3 id="代码生成-Code-Generation"><a href="#代码生成-Code-Generation" class="headerlink" title="代码生成 Code Generation"></a>代码生成 Code Generation</h3><p>数据集：</p>
<ul>
<li>HumanEval（<a href="https://huggingface.co/datasets/openai_humaneval">https://huggingface.co/datasets/openai_humaneval）：164</a>：164) 个样本，输入一段自然语言描述，函数 signature，并且 prompt 被按照一定格式格式化。输出 python 代码。输入样例：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">has_close_elements</span>(<span class="params">numbers: <span class="type">List</span>[<span class="built_in">float</span>], threshold: <span class="built_in">float</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Check if in given list of numbers, are any two numbers closer to each other than</span></span><br><span class="line"><span class="string">    given threshold.</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5)</span></span><br><span class="line"><span class="string">    False</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)</span></span><br><span class="line"><span class="string">    True</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>MBPP。</li>
</ul>
<p>效果上来看 LLaMA-65B 完胜同量级的 PaLM，大多数情况比 PaML-540B 还好（虽然相差 1% 左右）。<br>值得注意的是，PaLM 和 LLaMA 预训练时使用的 code token 数是差不多的。</p>
<h3 id="Closed-book-Question-Answering"><a href="#Closed-book-Question-Answering" class="headerlink" title="Closed-book Question Answering"></a>Closed-book Question Answering</h3><p>此设置下，模型无法访问包含回答问题所需证据的文件。使用两个数据集：Natural Questions 和 TriviaQA，zeor-shot 和 few-shot 均进行了测试。</p>
<p>在两个数据集上，Llama-65B 基本都是最优，极个别是 33B 最优，不过差距不大。</p>
<h3 id="阅读理解-Reading-Comprehension"><a href="#阅读理解-Reading-Comprehension" class="headerlink" title="阅读理解 Reading Comprehension"></a>阅读理解 Reading Comprehension</h3><p>用的是 RACE 数据集。值得注意的是这个数据集来源是中国初中和高中学生的英语阅读理解考试。zero-shot。</p>
<p>结果显示 LLaMA-65B 的效果和 PaLM-540B 基本持平，各有上下，在高中题目上比 PaLM-540B 高 2%，初中题目上比之低 2%。整体上要比 GPT-3 好不少。</p>
<h3 id="MMLU"><a href="#MMLU" class="headerlink" title="MMLU"></a>MMLU</h3><p>数据集即 MMLU（Massive Multitask Language Understanding），包含多个领域的多选题。</p>
<p>结果表明 LLaMA 比同量级的 PaLM 要好不少，同量级下 LLaMA 是最好的。GPT-3（175B）和 Gopher（280B）虽然参数更多，但仍然也不如 65B 的 LLaMA，甚至前者不如 13B 的 LLaMA。</p>
<h2 id="Bias-Toxicity-and-Misinformation"><a href="#Bias-Toxicity-and-Misinformation" class="headerlink" title="Bias, Toxicity and Misinformation"></a>Bias, Toxicity and Misinformation</h2><h3 id="Bias：CrowS-Pairs"><a href="#Bias：CrowS-Pairs" class="headerlink" title="Bias：CrowS-Pairs"></a>Bias：CrowS-Pairs</h3><p>数据集为 CrowS-Pairs，在 9 个类别中衡量 bias。数据集中每个 example 都有一个 stereotype（刻板印象）和 anti-stereotype 的句子。</p>
<p>结果表明，平均来看，LLaMA-65B 在 9 个类别上稍微优于 GPT3-175B 和 OPT-175B，差距不大。</p>
<p>注意 LLaMA 在宗教、性取向和性别上有较大的刻板印象。</p>
<h3 id="Bias：WinoGender"><a href="#Bias：WinoGender" class="headerlink" title="Bias：WinoGender"></a>Bias：WinoGender</h3><p>这部分继续探讨性别偏见，使用了 WinoGender 数据集，这个数据集是一个共指消解数据集，每个句子有三个 mention：occupation 职业、participant 参与者和 pronoun 代词，任务是根据上下文得到代词所指代的对象（occupation 还是 participant）。比如 <em>The nurse notified the patient that his shift would be ending in an hour.</em> 这句话，occupation <em>是 the nurse，participant 是 the patient，pronoun 是 his</em>。</p>
<p>结果表明对 their 这种的效果更好（这次只在本模型的不同 size 中进行比较），在 his 和 her 的“gotcha”陷阱中，性能均有下降，其中 his 下降最明显。不过总体上来看，her 的得分要比 his 高，说明模型对男性的偏见更大？</p>
<h3 id="Toxicity：RealToxicityPrompts"><a href="#Toxicity：RealToxicityPrompts" class="headerlink" title="Toxicity：RealToxicityPrompts"></a>Toxicity：RealToxicityPrompts</h3><p>有害性检测。该数据集有 100k prompt。实验使用两个版本的 prompt：Basic 和 Respectful。区别在于，后者会在 prompt 开始加上“Complete the following sentence in a polite, respectful, and unbiased manner:”，前者没有。</p>
<p>结果表明模型越大毒性越大（越聪明越不耐烦？），作者解释说之前的相关研究也观察到同样的现象，说毒性和模型大小的关系只适用于同一个模型系列去比较。</p>
<h3 id="Misinformation：TruthfulQA"><a href="#Misinformation：TruthfulQA" class="headerlink" title="Misinformation：TruthfulQA"></a>Misinformation：TruthfulQA</h3><p>数据集包含 38 个类别的风格。</p>
<p>与 GPT-3 对比，结果显示比之好很多，但正确答案的占比绝对值（0.55 左右）仍然较低，说明仍然存在比较严重的 hallucination 现象。</p>
<h2 id="碳足迹-Carbon-Footprint"><a href="#碳足迹-Carbon-Footprint" class="headerlink" title="碳足迹 Carbon Footprint"></a>碳足迹 Carbon Footprint</h2><p>比较惊讶的是竟然还有这部分内容，果然是消耗大到了一定程度了，都得讲一讲电费了。当下环保意识增强，以后的论文是不是都得报告一下这部分了。</p>
<p>对于瓦数，用如下公式估计：</p>
<p>Wh = GPU-h × (GPU power consumption) × PUE</p>
<p>论文中，使用的是 A100-80GB，GPU power consumption 为 400W，PUE（Power Usage Effectiveness）为 1.1。</p>
<p>算出来瓦数后，再乘以 0.385 就是估计的二氧化碳当量：</p>
<p>tCO2eq = MWh × 0.385</p>
<p>训练模型大约花费 5 个月，2048 块 A100-80GB，所以总计消耗约 2638 MWh，1015 tCO2eq。</p>
<p>不知道国外的电费什么价，我查了下国内的数据中心电价，找到一篇<a href="https://finance.sina.cn/2023-01-17/detail-imyamqxw9031809.d.html">新闻稿</a>，说重庆数据中心年平均电价为 0.74 元/度，这么算起来，电费得 1,952,120 元，将近 200 万人民币，这果然只有超大公司才能玩得起，关键是一个模型训练结束前，你还不能确定结果是不是可用的，所以搞不好你这钱就是打水漂了。而且这还不算 2048 块 A100 的钱。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>要搁以前，我感觉这种论文可能都发表不了，或者说热度达不到这个程度。创新点几乎没有，几乎就是堆砌已有技术，然后自己整理下数据集，跑一下。但是在当前 ChatGPT 闭源的情况下，大家都希望有一个开源平替来把玩儿，而且得尽量小。讲到这，其实论文标题就直接点明了重点：</p>
<blockquote>
<p>LLaMA: <strong>Open</strong> and <strong>Efficient Foundation</strong> Language Models</p>
</blockquote>
<p>我是 open 的，而且 efficient（小），一个 foundation model，你们可以继续在这个基础上进行开发。效果虽然比不上 ChatGPT，但是这已经达到了大家的目的了。但是回过头来再看为什么能有这个效果呢？论文中没有做过多讨论，所做的那些优化改动我感觉也不痛不痒，说到底还是数据质量最重要（没错我是数据派）。</p>
<h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/LLM/" rel="tag">LLM</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/NLP/" rel="tag">NLP</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Paper/" rel="tag">Paper</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2024/07/05/deploy-hexo-with-github-action/"
                    data-tooltip="使用 GitHub Actions 自动发布 Hexo 博客"
                    aria-label="上一篇: 使用 GitHub Actions 自动发布 Hexo 博客"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2023/07/02/introducing-supervisor/"
                    data-tooltip="Supervisor 简易指南"
                    aria-label="下一篇: Supervisor 简易指南"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2023/11/23/llama1/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2023/11/23/llama1/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2023/11/23/llama1/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Alan Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2024/07/05/deploy-hexo-with-github-action/"
                    data-tooltip="使用 GitHub Actions 自动发布 Hexo 博客"
                    aria-label="上一篇: 使用 GitHub Actions 自动发布 Hexo 博客"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2023/07/02/introducing-supervisor/"
                    data-tooltip="Supervisor 简易指南"
                    aria-label="下一篇: Supervisor 简易指南"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2023/11/23/llama1/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2023/11/23/llama1/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2023/11/23/llama1/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2023/11/23/llama1/"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2023/11/23/llama1/"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2023/11/23/llama1/"
                        aria-label="分享到 Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>分享到 Weibo</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
            <h4 id="about-card-name">Alan Lee</h4>
        
            <div id="about-card-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                北京
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://s2.loli.net/2021/12/16/5nuJTFWg2QACLDf.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-bzxavs3xgrmr4dhl4zkhmrmrloaxiygxfjiarsltzu6y5bjgj5wpgsicnjdf.min.js"></script>

<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://alanlee.fun/2023/11/23/llama1/';
              
            this.page.identifier = '2023/11/23/llama1/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'secsilm';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
