
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Alan Lee">
    <title>TensorFlow 中的线性回归 - Alan Lee</title>
    <meta name="author" content="Alan Lee">
    
        <meta name="keywords" content="hexo,python,tensorflow,pytorch,nlp,natural language processing,deep learning,machine learning,large language models,llms,">
    
    
        <link rel="icon" href="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png">
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"},"articleBody":"前面 有篇博文 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。\n\n\n训练数据本次使用的训练数据是美国房价数据，做了一些预处理，完整数据可从这里下载，原始数据共有1460行８１列，其中我选用了LotArea(房屋面积)和SalePrice(售价)两个变量来分别作为自变量和因变量，处理后样本个数为1140个，也就是说全部训练数据是一个11402的矩阵，部分数据如下所示：训练部分数据\n训练部分数据*\n\n模型本次使用的是线性回归模型 y=Wx+b 其中$W$为权重，$b$为偏置。具体地，$x$ 即为LotArea，$y$ 即为SalePrice。\n\n开始训练使用TensorFlow训练模型大致是这样的步骤：\n1. 设置各种超参数，例如学习率，迭代次数等；\n2. 定义变量和模型；\n3. 初始化变量;\n4. 正式开始训练.\n废话不多说上完整代码，代码里有注释：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from __future__ import print_function, divisionimport tensorflow as tfimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn# 我是在Jupyter Notebook里运行的，所以需要这行%matplotlib inline# 读入数据train = pd.read_csv(&quot;Dataset/train.csv&quot;)# 选取房屋面积小于１２０００的数据train = train[train[&#x27;LotArea&#x27;] &lt; 12000]train_X = train[&#x27;LotArea&#x27;].values.reshape(-1, 1)train_Y = train[&#x27;SalePrice&#x27;].values.reshape(-1, 1)n_samples = train_X.shape[0]# 学习率learning_rate = 2# 迭代次数training_epochs = 1000# 每多少次输出一次迭代结果display_step = 50# 这个X和Y和上面的train_X,train_Y是不一样的，这里只是个占位符，# 训练开始的时候需要“喂”(feed)数据给它X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)# 定义模型参数W = tf.Variable(np.random.randn(), name=&quot;weight&quot;, dtype=tf.float32)b = tf.Variable(np.random.randn(), name=&quot;bias&quot;, dtype=tf.float32)# 定义模型pred = tf.add(tf.mul(W, X), b)# 定义损失函数cost = tf.reduce_sum(tf.pow(pred-Y, 2)) / (2 * n_samples)# 使用Adam算法，至于为什么不使用一般的梯度下降算法，一会说optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)# 初始化所有变量init = tf.initialize_all_variables()# 训练开始with tf.Session() as sess:    sess.run(init)        for epoch in range(training_epochs):        for (x, y) in zip(train_X, train_Y):            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)        if (epoch + 1) % display_step == 0:            c = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;)            print(&quot;Epoch:&quot;, &#x27;%04d&#x27; % (epoch + 1), &quot;cost=&quot;, &quot;&#123;:.3f&#125;&quot;.format(c), &quot;W=&quot;, sess.run(W), &quot;b=&quot;, sess.run(b))        print(&quot;Optimization Finished!&quot;)    training_cost = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;)    print(&quot;Training cost=&quot;, training_cost, &quot;W=&quot;, sess.run(W), &quot;b=&quot;, sess.run(b), &#x27;\\n&#x27;)        # 画图    plt.plot(train_X, train_Y, &#x27;ro&#x27;, label=&quot;Original data&quot;)    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=&quot;Fitted line&quot;)    plt.legend()    plt.show()\n结果如下，\n12345678910111213141516171819202122Epoch: 0050 cost= 2283274240.000 W= 20.3469 b= 12945.2Epoch: 0100 cost= 2196306176.000 W= 19.0349 b= 24402.2Epoch: 0150 cost= 2128102656.000 W= 17.8766 b= 34479.1Epoch: 0200 cost= 2074902912.000 W= 16.8604 b= 43292.1Epoch: 0250 cost= 2033546240.000 W= 15.9735 b= 50965.1Epoch: 0300 cost= 2001452160.000 W= 15.2026 b= 57622.0Epoch: 0350 cost= 1976554496.000 W= 14.5348 b= 63380.2Epoch: 0400 cost= 1957219584.000 W= 13.9577 b= 68350.4Epoch: 0450 cost= 1942167424.000 W= 13.4598 b= 72634.2Epoch: 0500 cost= 1930414208.000 W= 13.0309 b= 76322.2Epoch: 0550 cost= 1921200000.000 W= 12.6619 b= 79494.2Epoch: 0600 cost= 1913948928.000 W= 12.3445 b= 82220.2Epoch: 0650 cost= 1908209664.000 W= 12.0717 b= 84562.8Epoch: 0700 cost= 1903651840.000 W= 11.8377 b= 86572.4Epoch: 0750 cost= 1900003456.000 W= 11.6364 b= 88299.7Epoch: 0800 cost= 1897074944.000 W= 11.4638 b= 89781.0Epoch: 0850 cost= 1894714880.000 W= 11.3161 b= 91048.3Epoch: 0900 cost= 1892792320.000 W= 11.189 b= 92139.5Epoch: 0950 cost= 1891217024.000 W= 11.0795 b= 93078.3Epoch: 1000 cost= 1889932800.000 W= 10.9862 b= 93879.3Optimization Finished!Training cost= 1.88993e+09 W= 10.9862 b= 93879.3 \n这里写图片描述\n\n几个问题\n在迭代次数相同的情况下，调节学习率能非常有效的改变损失的下降速度，刚开始学习率是0.001，结果非常的不好，损失比现在的大0.3e09左右，一步一步加大学习率效果显著，即使现在的２也不算大（对于这个问题），但是对于其他问题，要具体情况具体分析，这个学习率或许太过激进;\n至于优化算法为什么不选用更为常见的tf.train.GradientDescentOptimize,刚开始我也是用的这个算法，结果发现 cost, W, b 都是nan，Not a Number，后来当我每一次迭代都输出结果的时候，发现原来这几个值异常迅速的增大，导致超出了表示范围，如下,学习率为 0.001\n123456789101112131415161718192021Epoch: 0001 W= 1541.27 b= -0.811313Epoch: 0001 W= -121530.0 b= -13.6312Epoch: 0001 W= 1.33729e+07 b= 1185.87Epoch: 0001 W= -1.05648e+09 b= -110841.0Epoch: 0001 W= 9.3181e+10 b= 9.23441e+06Epoch: 0001 W= -8.717e+12 b= -8.39367e+08Epoch: 0001 W= 2.77678e+14 b= 4.59572e+10Epoch: 0001 W= -1.31328e+16 b= -1.76138e+12Epoch: 0001 W= 1.43194e+18 b= 1.27263e+14Epoch: 0001 W= -1.7716e+20 b= -1.48503e+16Epoch: 0001 W= 1.74557e+22 b= 1.64051e+18Epoch: 0001 W= -1.80845e+24 b= -1.65567e+20Epoch: 0001 W= 5.76078e+25 b= 9.54297e+21Epoch: 0001 W= -6.32776e+27 b= -5.585e+23Epoch: 0001 W= 6.40024e+29 b= 5.93388e+25Epoch: 0001 W= -3.14474e+31 b= -4.18503e+27Epoch: 0001 W= 1.4992e+33 b= 2.01299e+29Epoch: 0001 W= -1.23312e+35 b= -1.26103e+31Epoch: 0001 W= inf b= infEpoch: 0001 W= nan b= nanEpoch: 0001 W= nan b= nan\n其实就是正负跳的太厉害，而且貌似收敛不了。即使我减小学习率也是杯水车薪，后来试用了这个Adam（Adaptive Moment Estimation）算法，结果没有那个问题了，其实还有其他的算法，我还没有来得及一个一个试，如果想了解各种梯度下降算法，可以参考这篇文章：An overview of gradient descent optimization algorithms\n\n其实在这种简单的模型上，我个人觉得使用 sklearn 效率更高点（当然 TensorFlow 的定制性比较强，更为底层），我用 sklearn 实现了一次，效果很好，基本就是傻瓜式操作，效果如图，这里写图片描述\n可以看到两种方法得出的结果还是差不多的（当然TF更为繁琐些）。另外在耗时上，sklearn 也要明显快于 TF, sklearn 几乎是秒出，TF 每次迭代大概需要 11 秒。\n\n\n\nEND\n暂且就是这些，今天折腾了大半天，不容易啊，还是自己太嫩啦：）\n","dateCreated":"2016-10-22T08:53:57+08:00","dateModified":"2025-06-14T20:46:16+08:00","datePublished":"2016-10-22T08:53:57+08:00","description":"前面 有篇博文 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。","headline":"TensorFlow 中的线性回归","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"},"publisher":{"@type":"Organization","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png","logo":{"@type":"ImageObject","url":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"}},"url":"https://alanlee.fun/2016/10/22/tensorflow-linear-regression/","keywords":"Python, TensorFlow, Machine Learning"}</script>
    <meta name="description" content="前面 有篇博文 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。">
<meta property="og:type" content="blog">
<meta property="og:title" content="TensorFlow 中的线性回归">
<meta property="og:url" content="https://alanlee.fun/2016/10/22/tensorflow-linear-regression/index.html">
<meta property="og:site_name" content="Alan Lee">
<meta property="og:description" content="前面 有篇博文 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://img.blog.csdn.net/20161022194326754">
<meta property="og:image" content="http://img.blog.csdn.net/20161022201205063">
<meta property="og:image" content="http://img.blog.csdn.net/20161022203636514">
<meta property="article:published_time" content="2016-10-22T00:53:57.000Z">
<meta property="article:modified_time" content="2025-06-14T12:46:16.199Z">
<meta property="article:author" content="Alan Lee">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="TensorFlow">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://img.blog.csdn.net/20161022194326754">
<meta name="twitter:creator" content="@bluekirin93">
    
    
        
    
    
        <meta property="og:image" content="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-7psn7jtnqx8dcatt1chsgye58vhpeeqkf8gzcb5iijzope7gwcvezy8gigh2.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111553531-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111553531-1');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
        
    
    <style>
        ::-moz-selection { /* Code for Firefox */
          background: #FFBFBF;
        }
        
        ::selection {
          background: #FFBFBF;
        }
    </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Alan Lee
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Alan Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/secsilm"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/bluekirin93"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:secsilm@outlook.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            TensorFlow 中的线性回归
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2016-10-22T08:53:57+08:00">
	
		    2016 年 10 月 22 日
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>前面 <a href="http://blog.csdn.net/u010099080/article/details/52333935">有篇博文</a> 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。</p>
<span id="more"></span>
<hr>
<h1 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h1><p>本次使用的训练数据是美国房价数据，做了一些预处理，完整数据可从<a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">这里</a>下载，原始数据共有1460行８１列，其中我选用了LotArea(房屋面积)和SalePrice(售价)两个变量来分别作为自变量和因变量，处理后样本个数为1140个，也就是说全部训练数据是一个1140<em>2的矩阵，部分数据如下所示：<br><div class="figure center" style="width:;"><a class="fancybox" href="http://img.blog.csdn.net/20161022194326754" title="训练部分数据" data-caption="训练部分数据" data-fancybox="default"><img class="fig-img" src="http://img.blog.csdn.net/20161022194326754" alt="训练部分数据"></a><span class="caption">训练部分数据</span></div>
</em>训练部分数据*</p>
<hr>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>本次使用的是线性回归模型 <script type="math/tex">y=Wx+b</script> 其中$W$为权重，$b$为偏置。<br>具体地，$x$ 即为LotArea，$y$ 即为SalePrice。</p>
<hr>
<h1 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h1><p>使用TensorFlow训练模型大致是这样的步骤：</p>
<pre><code>1. 设置各种超参数，例如学习率，迭代次数等；
2. 定义变量和模型；
3. 初始化变量;
4. 正式开始训练.
</code></pre><p>废话不多说上完整代码，代码里有注释：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, division</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line"><span class="comment"># 我是在Jupyter Notebook里运行的，所以需要这行</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&quot;Dataset/train.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 选取房屋面积小于１２０００的数据</span></span><br><span class="line">train = train[train[<span class="string">&#x27;LotArea&#x27;</span>] &lt; <span class="number">12000</span>]</span><br><span class="line">train_X = train[<span class="string">&#x27;LotArea&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">train_Y = train[<span class="string">&#x27;SalePrice&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">n_samples = train_X.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learning_rate = <span class="number">2</span></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">training_epochs = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 每多少次输出一次迭代结果</span></span><br><span class="line">display_step = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个X和Y和上面的train_X,train_Y是不一样的，这里只是个占位符，</span></span><br><span class="line"><span class="comment"># 训练开始的时候需要“喂”(feed)数据给它</span></span><br><span class="line">X = tf.placeholder(tf.float32)</span><br><span class="line">Y = tf.placeholder(tf.float32)</span><br><span class="line"><span class="comment"># 定义模型参数</span></span><br><span class="line">W = tf.Variable(np.random.randn(), name=<span class="string">&quot;weight&quot;</span>, dtype=tf.float32)</span><br><span class="line">b = tf.Variable(np.random.randn(), name=<span class="string">&quot;bias&quot;</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">pred = tf.add(tf.mul(W, X), b)</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">cost = tf.reduce_sum(tf.<span class="built_in">pow</span>(pred-Y, <span class="number">2</span>)) / (<span class="number">2</span> * n_samples)</span><br><span class="line"><span class="comment"># 使用Adam算法，至于为什么不使用一般的梯度下降算法，一会说</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化所有变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练开始</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(training_epochs):</span><br><span class="line">        <span class="keyword">for</span> (x, y) <span class="keyword">in</span> <span class="built_in">zip</span>(train_X, train_Y):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            c = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>, <span class="string">&#x27;%04d&#x27;</span> % (epoch + <span class="number">1</span>), <span class="string">&quot;cost=&quot;</span>, <span class="string">&quot;&#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(c), <span class="string">&quot;W=&quot;</span>, sess.run(W), <span class="string">&quot;b=&quot;</span>, sess.run(b))</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Optimization Finished!&quot;</span>)</span><br><span class="line">    training_cost = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Training cost=&quot;</span>, training_cost, <span class="string">&quot;W=&quot;</span>, sess.run(W), <span class="string">&quot;b=&quot;</span>, sess.run(b), <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 画图</span></span><br><span class="line">    plt.plot(train_X, train_Y, <span class="string">&#x27;ro&#x27;</span>, label=<span class="string">&quot;Original data&quot;</span>)</span><br><span class="line">    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=<span class="string">&quot;Fitted line&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如下，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0050 cost= 2283274240.000 W= 20.3469 b= 12945.2</span><br><span class="line">Epoch: 0100 cost= 2196306176.000 W= 19.0349 b= 24402.2</span><br><span class="line">Epoch: 0150 cost= 2128102656.000 W= 17.8766 b= 34479.1</span><br><span class="line">Epoch: 0200 cost= 2074902912.000 W= 16.8604 b= 43292.1</span><br><span class="line">Epoch: 0250 cost= 2033546240.000 W= 15.9735 b= 50965.1</span><br><span class="line">Epoch: 0300 cost= 2001452160.000 W= 15.2026 b= 57622.0</span><br><span class="line">Epoch: 0350 cost= 1976554496.000 W= 14.5348 b= 63380.2</span><br><span class="line">Epoch: 0400 cost= 1957219584.000 W= 13.9577 b= 68350.4</span><br><span class="line">Epoch: 0450 cost= 1942167424.000 W= 13.4598 b= 72634.2</span><br><span class="line">Epoch: 0500 cost= 1930414208.000 W= 13.0309 b= 76322.2</span><br><span class="line">Epoch: 0550 cost= 1921200000.000 W= 12.6619 b= 79494.2</span><br><span class="line">Epoch: 0600 cost= 1913948928.000 W= 12.3445 b= 82220.2</span><br><span class="line">Epoch: 0650 cost= 1908209664.000 W= 12.0717 b= 84562.8</span><br><span class="line">Epoch: 0700 cost= 1903651840.000 W= 11.8377 b= 86572.4</span><br><span class="line">Epoch: 0750 cost= 1900003456.000 W= 11.6364 b= 88299.7</span><br><span class="line">Epoch: 0800 cost= 1897074944.000 W= 11.4638 b= 89781.0</span><br><span class="line">Epoch: 0850 cost= 1894714880.000 W= 11.3161 b= 91048.3</span><br><span class="line">Epoch: 0900 cost= 1892792320.000 W= 11.189 b= 92139.5</span><br><span class="line">Epoch: 0950 cost= 1891217024.000 W= 11.0795 b= 93078.3</span><br><span class="line">Epoch: 1000 cost= 1889932800.000 W= 10.9862 b= 93879.3</span><br><span class="line">Optimization Finished!</span><br><span class="line">Training cost= 1.88993e+09 W= 10.9862 b= 93879.3 </span><br></pre></td></tr></table></figure>
<div class="figure center" style="width:;"><a class="fancybox" href="http://img.blog.csdn.net/20161022201205063" title="这里写图片描述" data-caption="这里写图片描述" data-fancybox="default"><img class="fig-img" src="http://img.blog.csdn.net/20161022201205063" alt="这里写图片描述"></a><span class="caption">这里写图片描述</span></div>
<hr>
<h1 id="几个问题"><a href="#几个问题" class="headerlink" title="几个问题"></a>几个问题</h1><ol>
<li>在迭代次数相同的情况下，调节学习率能非常有效的改变损失的下降速度，刚开始学习率是0.001，结果非常的不好，损失比现在的大<strong>0.3e09</strong>左右，一步一步加大学习率效果显著，即使现在的２也不算大（对于这个问题），但是对于其他问题，要具体情况具体分析，这个学习率或许太过激进;</li>
<li><p>至于优化算法为什么不选用更为常见的<code>tf.train.GradientDescentOptimize</code>,刚开始我也是用的这个算法，结果发现 <code>cost</code>, <code>W</code>, <code>b</code> 都是<code>nan</code>，Not a Number，后来当我每一次迭代都输出结果的时候，发现原来这几个值异常迅速的增大，导致超出了表示范围，如下,学习率为 0.001</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 W= 1541.27 b= -0.811313</span><br><span class="line">Epoch: 0001 W= -121530.0 b= -13.6312</span><br><span class="line">Epoch: 0001 W= 1.33729e+07 b= 1185.87</span><br><span class="line">Epoch: 0001 W= -1.05648e+09 b= -110841.0</span><br><span class="line">Epoch: 0001 W= 9.3181e+10 b= 9.23441e+06</span><br><span class="line">Epoch: 0001 W= -8.717e+12 b= -8.39367e+08</span><br><span class="line">Epoch: 0001 W= 2.77678e+14 b= 4.59572e+10</span><br><span class="line">Epoch: 0001 W= -1.31328e+16 b= -1.76138e+12</span><br><span class="line">Epoch: 0001 W= 1.43194e+18 b= 1.27263e+14</span><br><span class="line">Epoch: 0001 W= -1.7716e+20 b= -1.48503e+16</span><br><span class="line">Epoch: 0001 W= 1.74557e+22 b= 1.64051e+18</span><br><span class="line">Epoch: 0001 W= -1.80845e+24 b= -1.65567e+20</span><br><span class="line">Epoch: 0001 W= 5.76078e+25 b= 9.54297e+21</span><br><span class="line">Epoch: 0001 W= -6.32776e+27 b= -5.585e+23</span><br><span class="line">Epoch: 0001 W= 6.40024e+29 b= 5.93388e+25</span><br><span class="line">Epoch: 0001 W= -3.14474e+31 b= -4.18503e+27</span><br><span class="line">Epoch: 0001 W= 1.4992e+33 b= 2.01299e+29</span><br><span class="line">Epoch: 0001 W= -1.23312e+35 b= -1.26103e+31</span><br><span class="line">Epoch: 0001 W= inf b= inf</span><br><span class="line">Epoch: 0001 W= nan b= nan</span><br><span class="line">Epoch: 0001 W= nan b= nan</span><br></pre></td></tr></table></figure>
<p>其实就是正负跳的太厉害，而且貌似收敛不了。即使我减小学习率也是杯水车薪，后来试用了这个Adam（Adaptive Moment Estimation）算法，结果没有那个问题了，其实还有其他的算法，我还没有来得及一个一个试，如果想了解各种梯度下降算法，可以参考这篇文章：<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">An overview of gradient descent optimization algorithms</a></p>
</li>
<li>其实在这种简单的模型上，我个人觉得使用 sklearn 效率更高点（当然 TensorFlow 的定制性比较强，更为底层），我用 sklearn 实现了一次，效果很好，基本就是傻瓜式操作，效果如图，<div class="figure center" style="width:;"><a class="fancybox" href="http://img.blog.csdn.net/20161022203636514" title="这里写图片描述" data-caption="这里写图片描述" data-fancybox="default"><img class="fig-img" src="http://img.blog.csdn.net/20161022203636514" alt="这里写图片描述"></a><span class="caption">这里写图片描述</span></div>
可以看到两种方法得出的结果还是差不多的（当然TF更为繁琐些）。另外在耗时上，sklearn 也要明显快于 TF, sklearn 几乎是秒出，TF 每次迭代大概需要 11 秒。</li>
</ol>
<hr>
<h1 id="table-of-contents">目录</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-text">训练数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-text">模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83"><span class="toc-text">开始训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98"><span class="toc-text">几个问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#END"><span class="toc-text">END</span></a></li></ol>
<h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1><!-- more -->
<p>暂且就是这些，今天折腾了大半天，不容易啊，还是自己太嫩啦：）</p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Python/" rel="tag">Python</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/10/26/sklearn-logistics-regression-parameters/"
                    data-tooltip="sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                    aria-label="上一篇: sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/08/27/ubuntu-installing-tensorflow/"
                    data-tooltip="Ubuntu 14.04 64 位安装 Google 的 TensorFlow"
                    aria-label="下一篇: Ubuntu 14.04 64 位安装 Google 的 TensorFlow"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Alan Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/10/26/sklearn-logistics-regression-parameters/"
                    data-tooltip="sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                    aria-label="上一篇: sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/08/27/ubuntu-installing-tensorflow/"
                    data-tooltip="Ubuntu 14.04 64 位安装 Google 的 TensorFlow"
                    aria-label="下一篇: Ubuntu 14.04 64 位安装 Google 的 TensorFlow"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/10/22/tensorflow-linear-regression/"
                        aria-label="分享到 Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>分享到 Weibo</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
            <h4 id="about-card-name">Alan Lee</h4>
        
            <div id="about-card-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                北京
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://s2.loli.net/2021/12/16/5nuJTFWg2QACLDf.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-bzxavs3xgrmr4dhl4zkhmrmrloaxiygxfjiarsltzu6y5bjgj5wpgsicnjdf.min.js"></script>

<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://alanlee.fun/2016/10/22/tensorflow-linear-regression/';
              
            this.page.identifier = '2016/10/22/tensorflow-linear-regression/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'secsilm';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
