
<!DOCTYPE html>
<html lang="zh-cn">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Alan Lee">
    <title>学习率、迭代次数和初始化方式对模型准确率的影响 - Alan Lee</title>
    <meta name="author" content="Alan Lee">
    
        <meta name="keywords" content="hexo,python,tensorflow,pytorch,nlp,natural language processing,deep learning,machine learning,large language models,llms,">
    
    
        <link rel="icon" href="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png">
    
    
        
            <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
        
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"},"articleBody":"想必学过机器学习的人都知道，学习率、训练迭代次数和模型参数的初始化方式都对模型最后的准确率有一定的影响，那么影响到底有多大呢？\n我初步做了个实验，在 TensorFlow 框架下使用 Logistics Regression 对经典的 MNIST 数据集进行分类。\n\n\n本文所说的 准确率 均指 测试准确率。\n\n代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&quot;/home/alan/data/&quot;, one_hot=True)from __future__ import print_functionimport tensorflow as tfimport matplotlib.pyplot as plt# 如果运行提示没有seaborn库，可以注释掉这行代码# 也可以使用 pip install seaborn或者 conda install seaborn安装import seaborn# 我是在Jupyter Notebook下运行的# 如果你是在命令行运行那么就注释掉下面这一行%matplotlib inline# 设置模型# 学习率learning_rate = 0.01# 训练迭代次数training_epochs = 50# batch大小batch_size = 100# 每多少次迭代显示一次损失display_step = 1x = tf.placeholder(tf.float32, [None, 784])y = tf.placeholder(tf.float32, [None, 10])# 模型参数# W = tf.Variable(tf.zeros([784, 10]))# b = tf.Variable(tf.zeros([10]))W = tf.Variable(tf.truncated_normal([784, 10]))b = tf.Variable(tf.truncated_normal([10]))# 建立模型pred = tf.nn.softmax(tf.matmul(x, W) + b)# 定义损失函数：交叉熵cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))# 梯度下降optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)# 初始化所有变量init = tf.initialize_all_variables()# 训练模型with tf.Session() as sess:    sess.run(init)        ax1 = plt.subplot(211)    ax1.set_ylabel(&quot;Accuracy&quot;)    ax2 = plt.subplot(212, sharex=ax1)    ax2.set_ylabel(&quot;Cost&quot;)    ax2.set_xlabel(&quot;Epoch&quot;)    plt.setp(ax1.get_xticklabels(), visible=False)        for epoch in range(training_epochs):        avg_cost = 0        total_batch = int(mnist.train.num_examples / batch_size)                for i in range(total_batch):            batch_xs, batch_ys = mnist.train.next_batch(batch_size)            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)                        avg_cost += c / total_batch                    if (epoch + 1) % display_step == 0:             # 计算测试准确率            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))                        ax1.plot(epoch+1, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;), &#x27;mo&#x27;)            ax2.plot(epoch+1, avg_cost, &#x27;co&#x27;)                         print(&quot;Epoch:&quot;, &#x27;%04d&#x27; % (epoch+1), &quot;cost=&quot;, &#x27;&#123;:.9f&#125;&#x27;.format(avg_cost), end=&#x27; &#x27;)            print(&quot;Accuracy:&quot;, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))                print(&quot;Optimization Finished!&quot;)        print(&quot;Accuracy:&quot;, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))    plt.suptitle(&quot;learning rate=%f, training epochs=%i, with tf.truncated_normal()&quot; % (learning_rate, training_epochs), size=14)    plt.savefig(&#x27;AC8.png&#x27;, dpi=300)    plt.show()\n通过修改 learning_rate 和 training_epochs来修改学习率和迭代次数，修改\n1234567# 所有变量初始化为0# W = tf.Variable(tf.zeros([784, 10]))# b = tf.Variable(tf.zeros([10]))# 所有变量初始化为符合标准截断正态分布的随机数W = tf.Variable(tf.truncated_normal([784, 10]))b = tf.Variable(tf.truncated_normal([10]))\n来修改变量的初始化方式。程序最终会输出损失和准确率随着迭代次数的变化趋势图。\n结果\n以下结果的背景是：TensorFlow，Logistics Regression，MNIST数据集，很可能换一个数据集下面的结论中的某一条就不成立啦，所以要具体情况具体分析，找到最优的超参数组合。\n\n多次的更改会输出多个不同的图，我们先来看下最终的准确率比较，然后再看下每种情况的详细的损失和准确率变化。\n符号说明\nlr：Learning Rate，学习率 \nte：Training Epochs，训练迭代次数\nz：tf.zeros()，变量初始化为0\nt：tf.truncated_normal()，变量初始化为标准截断正态分布的随机数\n\n最终准确率比较\n可以看到\n\n学习率为0.1，迭代次数为50次，并且采用随机初始化方式时准确率远远低于其他方式，甚至不足90%。而学习率为0.1，迭代次数为50次，并且采用随机初始化的方式时准确率最高。\n对于采用随机初始化的方式，在其他参数相同的情况下增大迭代次数会明显的提高准确率。而对于初始化为0的情况则无明显变化。\n其他参数相同的情况下，过度增大学习率的确是会导致准确率下降的，查看详细变化过程时可以看到准确率变化波动比较大。\n在学习率适中，迭代次数较大时变量初始化方式对最终准确率的影响不大。\n\n每种情况损失和准确率的详细变化趋势\n与上图的顺序保持一致，从上至下。每张图的标题在图的下面，斜体字。\n\n学习率为1，迭代次数为50，随机初始化\n\n学习率为1，迭代次数为50，初始化为0\n\n学习率为0.1，迭代次数为50，随机初始化\n\n学习率为0.1，迭代次数为50，初始化为0\n\n学习率为0.1，迭代次数为25，随机初始化\n\n学习率为0.1，迭代次数为25，初始化为0\n\n学习率为0.01，迭代次数为50，随机初始化\n\n学习率为0.01，迭代次数为50，初始化为0\n\n\n大部分情况下准确率和损失的变化时单调的，但是当学习率过大（=1）时准确率开始不稳定。\nEND暂且就是这么多，我说的难免有不合适的地方，有错误的地方欢迎指出。\n","dateCreated":"2016-10-29T04:46:50+08:00","dateModified":"2025-06-14T20:46:16+08:00","datePublished":"2016-10-29T04:46:50+08:00","description":"想必学过机器学习的人都知道，学习率、训练迭代次数和模型参数的初始化方式都对模型最后的准确率有一定的影响，那么影响到底有多大呢？\n我初步做了个实验，在 TensorFlow 框架下使用 Logistics Regression 对经典的 MNIST 数据集进行分类。","headline":"学习率、迭代次数和初始化方式对模型准确率的影响","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"},"publisher":{"@type":"Organization","name":"Alan Lee","sameAs":["https://github.com/secsilm","https://twitter.com/bluekirin93","mailto:secsilm@outlook.com"],"image":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png","logo":{"@type":"ImageObject","url":"https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"}},"url":"https://alanlee.fun/2016/10/29/tensorflow-hyperparams/","keywords":"Python, TensorFlow, Machine Learning"}</script>
    <meta name="description" content="想必学过机器学习的人都知道，学习率、训练迭代次数和模型参数的初始化方式都对模型最后的准确率有一定的影响，那么影响到底有多大呢？ 我初步做了个实验，在 TensorFlow 框架下使用 Logistics Regression 对经典的 MNIST 数据集进行分类。">
<meta property="og:type" content="blog">
<meta property="og:title" content="学习率、迭代次数和初始化方式对模型准确率的影响">
<meta property="og:url" content="https://alanlee.fun/2016/10/29/tensorflow-hyperparams/index.html">
<meta property="og:site_name" content="Alan Lee">
<meta property="og:description" content="想必学过机器学习的人都知道，学习率、训练迭代次数和模型参数的初始化方式都对模型最后的准确率有一定的影响，那么影响到底有多大呢？ 我初步做了个实验，在 TensorFlow 框架下使用 Logistics Regression 对经典的 MNIST 数据集进行分类。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://i.imgur.com/nTchbUv.png">
<meta property="og:image" content="http://i.imgur.com/aO85yQS.png">
<meta property="og:image" content="http://i.imgur.com/woxsj8h.png">
<meta property="og:image" content="http://i.imgur.com/Df5bWDw.png">
<meta property="og:image" content="http://i.imgur.com/5HEoBR2.png">
<meta property="og:image" content="http://i.imgur.com/ROX2pla.png">
<meta property="og:image" content="http://i.imgur.com/YbIsLq0.png">
<meta property="og:image" content="http://i.imgur.com/CDmZXao.png">
<meta property="og:image" content="http://i.imgur.com/R31MqQK.png">
<meta property="article:published_time" content="2016-10-28T20:46:50.000Z">
<meta property="article:modified_time" content="2025-06-14T12:46:16.198Z">
<meta property="article:author" content="Alan Lee">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="TensorFlow">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://i.imgur.com/nTchbUv.png">
<meta name="twitter:creator" content="@bluekirin93">
    
    
        
    
    
        <meta property="og:image" content="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-7psn7jtnqx8dcatt1chsgye58vhpeeqkf8gzcb5iijzope7gwcvezy8gigh2.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111553531-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111553531-1');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6e8b0c627bf164f809ee4346796b1952";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


    
        
    
    <style>
        ::-moz-selection { /* Code for Firefox */
          background: #FFBFBF;
        }
        
        ::selection {
          background: #FFBFBF;
        }
    </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Alan Lee
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打开链接: /#about"
            >
        
        
            <img class="header-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="阅读有关作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
                </a>
                <h4 class="sidebar-profile-name">Alan Lee</h4>
                
                    <h5 class="sidebar-profile-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="首页"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首页</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="标签"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">标签</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="归档"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">归档</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="关于"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">关于</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/secsilm"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/bluekirin93"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="mailto:secsilm@outlook.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="邮箱"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">邮箱</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            学习率、迭代次数和初始化方式对模型准确率的影响
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2016-10-29T04:46:50+08:00">
	
		    2016 年 10 月 29 日
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>想必学过机器学习的人都知道，学习率、训练迭代次数和模型参数的初始化方式都对模型最后的准确率有一定的影响，那么影响到底有多大呢？</p>
<p>我初步做了个实验，在 <code>TensorFlow</code> 框架下使用 Logistics Regression 对经典的 <code>MNIST</code> 数据集进行分类。</p>
<span id="more"></span>
<blockquote>
<p>本文所说的 <strong>准确率</strong> 均指 <strong>测试准确率</strong>。</p>
</blockquote>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;/home/alan/data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 如果运行提示没有seaborn库，可以注释掉这行代码</span></span><br><span class="line"><span class="comment"># 也可以使用 pip install seaborn或者 conda install seaborn安装</span></span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line"><span class="comment"># 我是在Jupyter Notebook下运行的</span></span><br><span class="line"><span class="comment"># 如果你是在命令行运行那么就注释掉下面这一行</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置模型</span></span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="comment"># 训练迭代次数</span></span><br><span class="line">training_epochs = <span class="number">50</span></span><br><span class="line"><span class="comment"># batch大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># 每多少次迭代显示一次损失</span></span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型参数</span></span><br><span class="line"><span class="comment"># W = tf.Variable(tf.zeros([784, 10]))</span></span><br><span class="line"><span class="comment"># b = tf.Variable(tf.zeros([10]))</span></span><br><span class="line">W = tf.Variable(tf.truncated_normal([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.truncated_normal([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">pred = tf.nn.softmax(tf.matmul(x, W) + b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数：交叉熵</span></span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化所有变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    </span><br><span class="line">    ax1 = plt.subplot(<span class="number">211</span>)</span><br><span class="line">    ax1.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">    ax2 = plt.subplot(<span class="number">212</span>, sharex=ax1)</span><br><span class="line">    ax2.set_ylabel(<span class="string">&quot;Cost&quot;</span>)</span><br><span class="line">    ax2.set_xlabel(<span class="string">&quot;Epoch&quot;</span>)</span><br><span class="line">    plt.setp(ax1.get_xticklabels(), visible=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(training_epochs):</span><br><span class="line">        avg_cost = <span class="number">0</span></span><br><span class="line">        total_batch = <span class="built_in">int</span>(mnist.train.num_examples / batch_size)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line">            </span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">             <span class="comment"># 计算测试准确率</span></span><br><span class="line">            correct_prediction = tf.equal(tf.argmax(pred, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">            </span><br><span class="line">            ax1.plot(epoch+<span class="number">1</span>, accuracy.<span class="built_in">eval</span>(&#123;x: mnist.test.images, y: mnist.test.labels&#125;), <span class="string">&#x27;mo&#x27;</span>)</span><br><span class="line">            ax2.plot(epoch+<span class="number">1</span>, avg_cost, <span class="string">&#x27;co&#x27;</span>) </span><br><span class="line">            </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>, <span class="string">&#x27;%04d&#x27;</span> % (epoch+<span class="number">1</span>), <span class="string">&quot;cost=&quot;</span>, <span class="string">&#x27;&#123;:.9f&#125;&#x27;</span>.<span class="built_in">format</span>(avg_cost), end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br><span class="line">            </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Optimization Finished!&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, accuracy.<span class="built_in">eval</span>(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br><span class="line">    plt.suptitle(<span class="string">&quot;learning rate=%f, training epochs=%i, with tf.truncated_normal()&quot;</span> % (learning_rate, training_epochs), size=<span class="number">14</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;AC8.png&#x27;</span>, dpi=<span class="number">300</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>通过修改 <code>learning_rate</code> 和 <code>training_epochs</code>来修改学习率和迭代次数，修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 所有变量初始化为0</span></span><br><span class="line"><span class="comment"># W = tf.Variable(tf.zeros([784, 10]))</span></span><br><span class="line"><span class="comment"># b = tf.Variable(tf.zeros([10]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有变量初始化为符合标准截断正态分布的随机数</span></span><br><span class="line">W = tf.Variable(tf.truncated_normal([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.truncated_normal([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>
<p>来修改变量的初始化方式。程序最终会输出损失和准确率随着迭代次数的变化趋势图。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><blockquote>
<p>以下结果的背景是：TensorFlow，Logistics Regression，MNIST数据集，很可能换一个数据集下面的结论中的某一条就不成立啦，所以要具体情况具体分析，找到最优的超参数组合。</p>
</blockquote>
<p>多次的更改会输出多个不同的图，我们先来看下最终的准确率比较，然后再看下每种情况的详细的损失和准确率变化。</p>
<h3 id="符号说明"><a href="#符号说明" class="headerlink" title="符号说明"></a>符号说明</h3><ul>
<li><code>lr</code>：Learning Rate，学习率 </li>
<li><code>te</code>：Training Epochs，训练迭代次数</li>
<li><code>z</code>：<code>tf.zeros()</code>，变量初始化为0</li>
<li><code>t</code>：<code>tf.truncated_normal()</code>，变量初始化为标准截断正态分布的随机数</li>
</ul>
<h3 id="最终准确率比较"><a href="#最终准确率比较" class="headerlink" title="最终准确率比较"></a>最终准确率比较</h3><p><img src="http://i.imgur.com/nTchbUv.png" alt=""></p>
<p>可以看到</p>
<ul>
<li>学习率为0.1，迭代次数为50次，并且采用随机初始化方式时准确率远远低于其他方式，甚至不足90%。而学习率为0.1，迭代次数为50次，并且采用随机初始化的方式时准确率最高。</li>
<li>对于采用随机初始化的方式，在其他参数相同的情况下增大迭代次数会明显的提高准确率。而对于初始化为0的情况则无明显变化。</li>
<li>其他参数相同的情况下，过度增大学习率<strong>的确是</strong>会导致准确率下降的，查看详细变化过程时可以看到准确率变化波动比较大。</li>
<li>在学习率适中，迭代次数较大时变量初始化方式对最终准确率的影响不大。</li>
</ul>
<h3 id="每种情况损失和准确率的详细变化趋势"><a href="#每种情况损失和准确率的详细变化趋势" class="headerlink" title="每种情况损失和准确率的详细变化趋势"></a>每种情况损失和准确率的详细变化趋势</h3><blockquote>
<p>与上图的顺序保持一致，从上至下。<br>每张图的标题在图的下面，斜体字。</p>
</blockquote>
<p><img src="http://i.imgur.com/aO85yQS.png" alt=""><br><em>学习率为1，迭代次数为50，随机初始化</em></p>
<hr>
<p><img src="http://i.imgur.com/woxsj8h.png" alt=""><br><em>学习率为1，迭代次数为50，初始化为0</em></p>
<hr>
<p><img src="http://i.imgur.com/Df5bWDw.png" alt=""><br><em>学习率为0.1，迭代次数为50，随机初始化</em></p>
<hr>
<p><img src="http://i.imgur.com/5HEoBR2.png" alt=""><br><em>学习率为0.1，迭代次数为50，初始化为0</em></p>
<hr>
<p><img src="http://i.imgur.com/ROX2pla.png" alt=""><br><em>学习率为0.1，迭代次数为25，随机初始化</em></p>
<hr>
<p><img src="http://i.imgur.com/YbIsLq0.png" alt=""><br><em>学习率为0.1，迭代次数为25，初始化为0</em></p>
<hr>
<p><img src="http://i.imgur.com/CDmZXao.png" alt=""><br><em>学习率为0.01，迭代次数为50，随机初始化</em></p>
<hr>
<p><img src="http://i.imgur.com/R31MqQK.png" alt=""><br><em>学习率为0.01，迭代次数为50，初始化为0</em></p>
<hr>
<h1 id="table-of-contents">目录</h1><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-text">代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-text">结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E"><span class="toc-text">符号说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E5%87%86%E7%A1%AE%E7%8E%87%E6%AF%94%E8%BE%83"><span class="toc-text">最终准确率比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%8F%E7%A7%8D%E6%83%85%E5%86%B5%E6%8D%9F%E5%A4%B1%E5%92%8C%E5%87%86%E7%A1%AE%E7%8E%87%E7%9A%84%E8%AF%A6%E7%BB%86%E5%8F%98%E5%8C%96%E8%B6%8B%E5%8A%BF"><span class="toc-text">每种情况损失和准确率的详细变化趋势</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#END"><span class="toc-text">END</span></a></li></ol>
<p>大部分情况下准确率和损失的变化时单调的，但是当学习率过大（<code>=1</code>）时准确率开始不稳定。<br><!-- more --></p>
<h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2><p>暂且就是这么多，我说的难免有不合适的地方，有错误的地方欢迎指出。</p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">标签</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Python/" rel="tag">Python</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/11/06/tensorflow-logistic-regression/"
                    data-tooltip="TensorFlow 中的 Logistic Regression"
                    aria-label="上一篇: TensorFlow 中的 Logistic Regression"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/10/26/sklearn-logistics-regression-parameters/"
                    data-tooltip="sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                    aria-label="下一篇: sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Alan Lee. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/11/06/tensorflow-logistic-regression/"
                    data-tooltip="TensorFlow 中的 Logistic Regression"
                    aria-label="上一篇: TensorFlow 中的 Logistic Regression"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2016/10/26/sklearn-logistics-regression-parameters/"
                    data-tooltip="sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                    aria-label="下一篇: sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                    title="分享到 Facebook"
                    aria-label="分享到 Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                    title="分享到 Twitter"
                    aria-label="分享到 Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                    title="分享到 Weibo"
                    aria-label="分享到 Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#disqus_thread"
                        aria-label="Kommentieren"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="目录">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                        aria-label="分享到 Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>分享到 Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                        aria-label="分享到 Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>分享到 Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://alanlee.fun/2016/10/29/tensorflow-hyperparams/"
                        aria-label="分享到 Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>分享到 Weibo</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://s2.loli.net/2021/12/19/Cri1WMHedxFm3pv.png" alt="作者的图片"/>
        
            <h4 id="about-card-name">Alan Lee</h4>
        
            <div id="about-card-bio"><p>NLP and Python developer, sometimes datavis, he/him. Stick to what you believe.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                北京
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://s2.loli.net/2021/12/16/5nuJTFWg2QACLDf.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-bzxavs3xgrmr4dhl4zkhmrmrloaxiygxfjiarsltzu6y5bjgj5wpgsicnjdf.min.js"></script>

<!--SCRIPTS END-->


    
        <script>
          var disqus_config = function() {
            this.page.url = 'https://alanlee.fun/2016/10/29/tensorflow-hyperparams/';
              
            this.page.identifier = '2016/10/29/tensorflow-hyperparams/';
              
          };
          (function() {
            var d = document, s = d.createElement('script');
            var disqus_shortname = 'secsilm';
            s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
    




    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
