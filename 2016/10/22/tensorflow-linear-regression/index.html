<!DOCTYPE html>
<html>
    <head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" >
    <title>
        
        TensorFlow 中的线性回归 · Lee&#39;s Space Station
        
    </title>
    <link rel="icon" href= /avatar/Bastion_cute.png>
    <!-- TODO: 在font-face加载完毕后改变字体  -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.28/webfontloader.js"></script>
    <!-- 提前加载place holder  -->
    <style type="text/css">
        @font-face {
            font-family: 'Oswald-Regular';
            src: url(/font/Oswald-Regular.ttf);
        }
    </style>
    <style type="text/css">
        .site-intro {
            position: relative;
            width: 100%;
            height: 50vh;
            overflow: hidden;
            box-shadow: -0.1rem 0 0.5rem 0 rgba(0, 0, 0, 0.8);
        }
        .site-intro-placeholder {
            position: absolute;
            z-index: -2;
            top: 0;
            left: 0px;
            width: calc(100% + 300px);
            height: 100%;
            background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
            background-position: center center;
            transform: translate3d(-226px, 0, 0);
            animation: gradient-move 2.5s ease-out 0s 1;
        }
        @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>
    <link rel="stylesheet" href = /css/style.css?v=20171218 />
    <script src="//cdn.staticfile.org/jquery/3.2.1/jquery.min.js" defer></script>
    
    <script src="/scripts/main.js" defer></script>
    <!-- 百度统计  -->
    
    <script>
        var _hmt = _hmt || [];
        (function () {
        var hm = document.createElement("script");
        hm.src = "6e8b0c627bf164f809ee4346796b1952";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
    <!-- 谷歌统计  -->
    
    <script>
        (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-111553531-1', 'auto');
        ga('send', 'pageview');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>
    
        <body class="post-body">
    
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Lee&#39;s Space Station</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">TensorFlow 中的线性回归</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Lee's Space Station</a>
</header>
    <div class="wrapper">
        <div class="site-intro">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-img" style="background-image: url(/assets/hanamura-3.jpg)"></div>
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            TensorFlow 中的线性回归
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <!-- 文章页标签  -->
            
                <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-href = Machine Learning>Machine Learning</a>
    
        <a class="post-tag" href="javascript:void(0);" data-href = TensorFlow>TensorFlow</a>
    
        <a class="post-tag" href="javascript:void(0);" data-href = Python>Python</a>
    
</div>
            
            <div class="post-intro-meta">
                <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                <span class="post-intro-time">2016/10/22</span>
            </div>
        
    </div>
</div>
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <script>
            var browser = {
                    versions: function () {
                        var u = window.navigator.userAgent;
                        return {
                            userAgent: u,
                            trident: u.indexOf('Trident') > -1, //IE内核
                            presto: u.indexOf('Presto') > -1, //opera内核
                            webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
                            gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
                            mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
                            ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
                            android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
                            iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
                            iPad: u.indexOf('iPad') > -1, //是否为iPad
                            webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
                            weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
                            uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
                        };
                    }()
                }

            function fontLoaded(){
                console.log('font loaded');
                if (document.getElementsByClassName('site-intro-meta')) {
                    document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
                    document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
                    var postIntroTags = document.getElementsByClassName('post-intro-tags')[0],
                        postIntroMeat = document.getElementsByClassName('post-intro-meta')[0];
                        if (postIntroTags) {
                            postIntroTags.classList.add('post-fade-in');
                        }
                        if (postIntroMeat) {
                            postIntroMeat.classList.add('post-fade-in');
                        }
                    }
                }
                
            console.log("userAgent:" + browser.versions.userAgent);
            // UC不支持跨域，所以直接显示
            if (browser.versions.uc) {
                console.log("UCBrowser");
                fontLoaded();
            } else {
                WebFont.load({
                    custom: {
                        families: ['Oswald-Regular']
                    },
                    loading: function () {  //所有字体开始加载
                        // console.log('loading');
                    },
                    active: function () {  //所有字体已渲染
                        fontLoaded();
                    },
                    inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
                        console.log('inactive: timeout');
                        fontLoaded();
                    },
                    timeout: 7000 // Set the timeout to two seconds
                });
            }
        </script>
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <p>前面 <a href="http://blog.csdn.net/u010099080/article/details/52333935" target="_blank" rel="noopener">有篇博文</a> 讲了讲Ubuntu环境下安装TensorFlow，今天来说一说在TensorFlow中如何进行线性回归。</p>
<a id="more"></a>
<hr>
<h1 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h1><p>本次使用的训练数据是美国房价数据，做了一些预处理，完整数据可从<a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" target="_blank" rel="noopener">这里</a>下载，原始数据共有1460行８１列，其中我选用了LotArea(房屋面积)和SalePrice(售价)两个变量来分别作为自变量和因变量，处理后样本个数为1140个，也就是说全部训练数据是一个1140<em>2的矩阵，部分数据如下所示：<br><img src="http://img.blog.csdn.net/20161022194326754" alt="训练部分数据">
</em>训练部分数据*</p>
<hr>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>本次使用的是线性回归模型 <script type="math/tex">y=Wx+b</script> 其中$W$为权重，$b$为偏置。<br>具体地，$x$ 即为LotArea，$y$ 即为SalePrice。</p>
<hr>
<h1 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h1><p>使用TensorFlow训练模型大致是这样的步骤：</p>
<pre><code>1. 设置各种超参数，例如学习率，迭代次数等；
2. 定义变量和模型；
3. 初始化变量;
4. 正式开始训练.
</code></pre><p>废话不多说上完整代码，代码里有注释：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, division</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line"><span class="comment"># 我是在Jupyter Notebook里运行的，所以需要这行</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">"Dataset/train.csv"</span>)</span><br><span class="line"><span class="comment"># 选取房屋面积小于１２０００的数据</span></span><br><span class="line">train = train[train[<span class="string">'LotArea'</span>] &lt; <span class="number">12000</span>]</span><br><span class="line">train_X = train[<span class="string">'LotArea'</span>].values.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">train_Y = train[<span class="string">'SalePrice'</span>].values.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">n_samples = train_X.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learning_rate = <span class="number">2</span></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">training_epochs = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 每多少次输出一次迭代结果</span></span><br><span class="line">display_step = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个X和Y和上面的train_X,train_Y是不一样的，这里只是个占位符，</span></span><br><span class="line"><span class="comment"># 训练开始的时候需要“喂”(feed)数据给它</span></span><br><span class="line">X = tf.placeholder(tf.float32)</span><br><span class="line">Y = tf.placeholder(tf.float32)</span><br><span class="line"><span class="comment"># 定义模型参数</span></span><br><span class="line">W = tf.Variable(np.random.randn(), name=<span class="string">"weight"</span>, dtype=tf.float32)</span><br><span class="line">b = tf.Variable(np.random.randn(), name=<span class="string">"bias"</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">pred = tf.add(tf.mul(W, X), b)</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">cost = tf.reduce_sum(tf.pow(pred-Y, <span class="number">2</span>)) / (<span class="number">2</span> * n_samples)</span><br><span class="line"><span class="comment"># 使用Adam算法，至于为什么不使用一般的梯度下降算法，一会说</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化所有变量</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练开始</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epochs):</span><br><span class="line">        <span class="keyword">for</span> (x, y) <span class="keyword">in</span> zip(train_X, train_Y):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">            c = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;)</span><br><span class="line">            print(<span class="string">"Epoch:"</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">"cost="</span>, <span class="string">"&#123;:.3f&#125;"</span>.format(c), <span class="string">"W="</span>, sess.run(W), <span class="string">"b="</span>, sess.run(b))</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br><span class="line">    training_cost = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;)</span><br><span class="line">    print(<span class="string">"Training cost="</span>, training_cost, <span class="string">"W="</span>, sess.run(W), <span class="string">"b="</span>, sess.run(b), <span class="string">'\n'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 画图</span></span><br><span class="line">    plt.plot(train_X, train_Y, <span class="string">'ro'</span>, label=<span class="string">"Original data"</span>)</span><br><span class="line">    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=<span class="string">"Fitted line"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如下，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0050 cost= 2283274240.000 W= 20.3469 b= 12945.2</span><br><span class="line">Epoch: 0100 cost= 2196306176.000 W= 19.0349 b= 24402.2</span><br><span class="line">Epoch: 0150 cost= 2128102656.000 W= 17.8766 b= 34479.1</span><br><span class="line">Epoch: 0200 cost= 2074902912.000 W= 16.8604 b= 43292.1</span><br><span class="line">Epoch: 0250 cost= 2033546240.000 W= 15.9735 b= 50965.1</span><br><span class="line">Epoch: 0300 cost= 2001452160.000 W= 15.2026 b= 57622.0</span><br><span class="line">Epoch: 0350 cost= 1976554496.000 W= 14.5348 b= 63380.2</span><br><span class="line">Epoch: 0400 cost= 1957219584.000 W= 13.9577 b= 68350.4</span><br><span class="line">Epoch: 0450 cost= 1942167424.000 W= 13.4598 b= 72634.2</span><br><span class="line">Epoch: 0500 cost= 1930414208.000 W= 13.0309 b= 76322.2</span><br><span class="line">Epoch: 0550 cost= 1921200000.000 W= 12.6619 b= 79494.2</span><br><span class="line">Epoch: 0600 cost= 1913948928.000 W= 12.3445 b= 82220.2</span><br><span class="line">Epoch: 0650 cost= 1908209664.000 W= 12.0717 b= 84562.8</span><br><span class="line">Epoch: 0700 cost= 1903651840.000 W= 11.8377 b= 86572.4</span><br><span class="line">Epoch: 0750 cost= 1900003456.000 W= 11.6364 b= 88299.7</span><br><span class="line">Epoch: 0800 cost= 1897074944.000 W= 11.4638 b= 89781.0</span><br><span class="line">Epoch: 0850 cost= 1894714880.000 W= 11.3161 b= 91048.3</span><br><span class="line">Epoch: 0900 cost= 1892792320.000 W= 11.189 b= 92139.5</span><br><span class="line">Epoch: 0950 cost= 1891217024.000 W= 11.0795 b= 93078.3</span><br><span class="line">Epoch: 1000 cost= 1889932800.000 W= 10.9862 b= 93879.3</span><br><span class="line">Optimization Finished!</span><br><span class="line">Training cost= 1.88993e+09 W= 10.9862 b= 93879.3</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20161022201205063" alt="这里写图片描述"></p>
<hr>
<h1 id="几个问题"><a href="#几个问题" class="headerlink" title="几个问题"></a>几个问题</h1><ol>
<li>在迭代次数相同的情况下，调节学习率能非常有效的改变损失的下降速度，刚开始学习率是0.001，结果非常的不好，损失比现在的大<strong>0.3e09</strong>左右，一步一步加大学习率效果显著，即使现在的２也不算大（对于这个问题），但是对于其他问题，要具体情况具体分析，这个学习率或许太过激进;</li>
<li><p>至于优化算法为什么不选用更为常见的<code>tf.train.GradientDescentOptimize</code>,刚开始我也是用的这个算法，结果发现 <code>cost</code>, <code>W</code>, <code>b</code> 都是<code>nan</code>，Not a Number，后来当我每一次迭代都输出结果的时候，发现原来这几个值异常迅速的增大，导致超出了表示范围，如下,学习率为 0.001</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 W= 1541.27 b= -0.811313</span><br><span class="line">Epoch: 0001 W= -121530.0 b= -13.6312</span><br><span class="line">Epoch: 0001 W= 1.33729e+07 b= 1185.87</span><br><span class="line">Epoch: 0001 W= -1.05648e+09 b= -110841.0</span><br><span class="line">Epoch: 0001 W= 9.3181e+10 b= 9.23441e+06</span><br><span class="line">Epoch: 0001 W= -8.717e+12 b= -8.39367e+08</span><br><span class="line">Epoch: 0001 W= 2.77678e+14 b= 4.59572e+10</span><br><span class="line">Epoch: 0001 W= -1.31328e+16 b= -1.76138e+12</span><br><span class="line">Epoch: 0001 W= 1.43194e+18 b= 1.27263e+14</span><br><span class="line">Epoch: 0001 W= -1.7716e+20 b= -1.48503e+16</span><br><span class="line">Epoch: 0001 W= 1.74557e+22 b= 1.64051e+18</span><br><span class="line">Epoch: 0001 W= -1.80845e+24 b= -1.65567e+20</span><br><span class="line">Epoch: 0001 W= 5.76078e+25 b= 9.54297e+21</span><br><span class="line">Epoch: 0001 W= -6.32776e+27 b= -5.585e+23</span><br><span class="line">Epoch: 0001 W= 6.40024e+29 b= 5.93388e+25</span><br><span class="line">Epoch: 0001 W= -3.14474e+31 b= -4.18503e+27</span><br><span class="line">Epoch: 0001 W= 1.4992e+33 b= 2.01299e+29</span><br><span class="line">Epoch: 0001 W= -1.23312e+35 b= -1.26103e+31</span><br><span class="line">Epoch: 0001 W= inf b= inf</span><br><span class="line">Epoch: 0001 W= nan b= nan</span><br><span class="line">Epoch: 0001 W= nan b= nan</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>其实就是正负跳的太厉害，而且貌似收敛不了。即使我减小学习率也是杯水车薪，后来试用了这个Adam（Adaptive Moment Estimation）算法，结果没有那个问题了，其实还有其他的算法，我还没有来得及一个一个试，如果想了解各种梯度下降算法，可以参考这篇文章：<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms</a></p>
<ol>
<li>其实在这种简单的模型上，我个人觉得使用 sklearn 效率更高点（当然 TensorFlow 的定制性比较强，更为底层），我用 sklearn 实现了一次，效果很好，基本就是傻瓜式操作，效果如图，<br><img src="http://img.blog.csdn.net/20161022203636514" alt="这里写图片描述"><br>可以看到两种方法得出的结果还是差不多的（当然TF更为繁琐些）。另外在耗时上，sklearn 也要明显快于 TF, sklearn 几乎是秒出，TF 每次迭代大概需要 11 秒。</li>
</ol>
<hr>
<h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1><p>暂且就是这些，今天折腾了大半天，不容易啊，还是自己太嫩啦：）</p>

    </article>
    <!-- 前后页  -->
    <ul class="post-pager">
        
            <li class="next">
                <a href= "/2016/10/24/plt-save/" title= 解决使用 plt.savefig 保存图片时一片空白 >
                    <span>Next Post</span>
                    <span>解决使用 plt.savefig 保存图片时一片空白</span>
                </a>
            </li>
        
        
            <li class="previous">
                <a href= "/2016/10/16/python-email/" title= 用 Python 发电子邮件 >
                    <span>Previous Post</span>
                    <span>用 Python 发电子邮件</span>
                </a>
            </li>
        
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    <div id="disqus_thread"></div>
    <script>
        /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
        
        var disqus_config = function () {
        this.page.url = "http://yoursite.com/2016/10/22/tensorflow-linear-regression/";  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = "TensorFlow 中的线性回归"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        
        (function () { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://secsilm.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();

    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

    
    <!--PC版-->

    <!--PC版-->


    
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:secsilm@outlook.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/secsilm" class="iconfont-archer github" target="_blank" title="github"></a>
            
        
    
        
            
                <a href="https://twitter.com/SilverSecondMan" class="iconfont-archer twitter" target="_blank" title="twitter"></a>
            
        
    
        
            
                <a href="https://www.instagram.com/secsilm/" class="iconfont-archer instagram" target="_blank" title="instagram"></a>
            
        
    
        
            
                <a href="/atom.xml" class="iconfont-archer rss" target="_blank" title="rss"></a>
            
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">Theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper">
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#训练数据"><span class="toc-number">1.</span> <span class="toc-text">训练数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型"><span class="toc-number">2.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#开始训练"><span class="toc-number">3.</span> <span class="toc-text">开始训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#几个问题"><span class="toc-number">4.</span> <span class="toc-text">几个问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#END"><span class="toc-number">5.</span> <span class="toc-text">END</span></a></li></ol>
    </div>
    
    <div class="back-top">&#xe639;</div>
    <div class="sidebar">
    <div class="sidebar-header sidebar-header-show-archive">
        <div class="sidebar-category">
            <span class="sidebar-archive-link"><span class="iconfont-archer">&#xe67d;</span>Archive</span>
            <span class="sidebar-tags-link"><span class="iconfont-archer">&#xe610;</span>Tag</span>
        </div>
    </div>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-archive">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-archive"> Total : 41 </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2017 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/22</span><a class="archive-post-title" href= "/2017/12/22/understanding-estimators-datasets/" >理解 Estimators 和 Datasets</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/26</span><a class="archive-post-title" href= "/2017/10/26/windows10-dark-theme/" >Windows 10 资源管理器黑色风格</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/08</span><a class="archive-post-title" href= "/2017/10/08/gradient-descent-methods/" >梯度下降优化算法概述</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/30</span><a class="archive-post-title" href= "/2017/08/30/ensemble-methods/" >使用集成学习提升机器学习算法性能</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/20</span><a class="archive-post-title" href= "/2017/08/20/understanding-tensorboard/" >理解 TensorBoard</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/17</span><a class="archive-post-title" href= "/2017/06/17/numpy-shuffle-permutation/" >Numpy 中的 shuffle VS permutation</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/02</span><a class="archive-post-title" href= "/2017/06/02/tensorflow-DNNRegressor/" >TensorFlow DNNRegressor 的简单使用</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/18</span><a class="archive-post-title" href= "/2017/05/18/installing-xgboost/" >XGBoost 在 Windows 10 和 Ubuntu 上的安装</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/22</span><a class="archive-post-title" href= "/2017/04/22/python-fire/" >Python 自动生成命令行工具 - fire 简介</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/29</span><a class="archive-post-title" href= "/2017/03/29/understanding-svd/" >奇异值分解 SVD 的数学解释</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/25</span><a class="archive-post-title" href= "/2017/03/25/python-string-count/" >使用 Python 统计字符串中英文、空格、数字、标点个数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/17</span><a class="archive-post-title" href= "/2017/03/17/tensorflow-cnn-tensorboard/" >TensorFlow 中的卷积神经网络 CNN - TensorBoard 版</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/15</span><a class="archive-post-title" href= "/2017/03/15/using-tree/" >使用 tree 命令格式化输出目录结构</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/11</span><a class="archive-post-title" href= "/2017/03/11/vscode-pdf-error/" >VSCode Markdown PDF 导出成PDF报 phantomjs binary does not exist 错误的解决办法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2017/03/01/numpy-copy/" >Numpy 中的 copy 问题详解</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/26</span><a class="archive-post-title" href= "/2017/02/26/tensorflow-cudnn-version/" >Check failed stream->parent()->GetConvolveAlgorithms(&algorithms)解决办法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/16</span><a class="archive-post-title" href= "/2017/02/16/tensorflow-1.0/" >TensorFlow 1.0 发布</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2016 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/28</span><a class="archive-post-title" href= "/2016/12/28/tensorflow-cnn-no-tensorboard/" >TensorFlow 中的卷积神经网络 CNN - 无TensorBoard版</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/10</span><a class="archive-post-title" href= "/2016/12/10/tensorboard-mnist-pca/" >在 TensorBoard 中用 PCA 可视化 MNIST 手写数字识别数据集</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/01</span><a class="archive-post-title" href= "/2016/12/01/installing-tensorflow/" >Windows10 64 位下安装 TensorFlow - 官方原生支持</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/30</span><a class="archive-post-title" href= "/2016/11/30/numpy-array-memory/" >小谈 Numpy 数组占用内存空间问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/19</span><a class="archive-post-title" href= "/2016/11/19/tensorflow-mlp/" >TensorFlow 中的多层感知器（MLP）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/06</span><a class="archive-post-title" href= "/2016/11/06/tensorflow-logistic-regression/" >TensorFlow 中的 Logistic Regression</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/03</span><a class="archive-post-title" href= "/2016/11/03/pandas-apply/" >Pandas 中的 apply 函数使用示例</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/29</span><a class="archive-post-title" href= "/2016/10/29/tensorflow-hyperparams/" >学习率、迭代次数和初始化方式对模型准确率的影响</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/26</span><a class="archive-post-title" href= "/2016/10/26/sklearn-logistics-regression-parameters/" >sklearn 中 Logistics Regression 的 coef_ 和 intercept_ 的具体意义</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/24</span><a class="archive-post-title" href= "/2016/10/24/plt-save/" >解决使用 plt.savefig 保存图片时一片空白</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/22</span><a class="archive-post-title" href= "/2016/10/22/tensorflow-linear-regression/" >TensorFlow 中的线性回归</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/16</span><a class="archive-post-title" href= "/2016/10/16/python-email/" >用 Python 发电子邮件</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/27</span><a class="archive-post-title" href= "/2016/08/27/ubuntu-installing-tensorflow/" >Ubuntu 14.04 64 位安装 Google 的 TensorFlow</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/22</span><a class="archive-post-title" href= "/2016/08/22/ubuntu-update-issue/" >Ubuntu 14.04 64 位系统更新重启后无法进入系统，光标不停闪烁</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/27</span><a class="archive-post-title" href= "/2016/06/27/python-strptime/" >Python 中 strptime 的简单使用</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/03</span><a class="archive-post-title" href= "/2016/04/03/python-numpy/" >Python NumPy 基础</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/24</span><a class="archive-post-title" href= "/2016/03/24/ubuntu-gedit-change-theme/" >Ubuntu14.04 gnome3 下 gedit 首选项消失时如何修改 gedit 主题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/18</span><a class="archive-post-title" href= "/2016/01/18/matlab-plot-parallelepiped/" >MATLAB绘制平行六面体</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/11</span><a class="archive-post-title" href= "/2016/01/11/matlab-mat2cell/" >MATLAB 矩阵分块函数 mat2cell 及 cellfun 函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/11</span><a class="archive-post-title" href= "/2016/01/11/machine-learning-book-note/" >《机器学习》学习笔记1——绪论 机器学习概述</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2015 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/21</span><a class="archive-post-title" href= "/2015/12/21/matlab-fitlm/" >使用 MATLAB 的 fitlm 函数进行线性回归</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/19</span><a class="archive-post-title" href= "/2015/11/19/matlab-rename-files/" >MATLAB 批量文件重命名（详细解释）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/05</span><a class="archive-post-title" href= "/2015/11/05/matlab-callback/" >MATLAB GUI 中 Edit Text 的 Callback 函数何时执行</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2015/09/22/matlab-move-files/" >用 MATLAB 将多个文件夹内的某些文件汇总到另一个文件夹</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name"><a href= "#">Machine Learning</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Translation</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">TensorFlow</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Data Science</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">MATLAB</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Python</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">sklearn</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Ubuntu</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">IDE</a></span>
    
        <span class="sidebar-tag-name"><a href= "#">Windows</a></span>
    
    </div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: false
    tags: true</pre>
    </div> 
    <div class="sidebar-tag-list"></div>
</div>
    </div>
</div> 
    <script>
    var jsInfo = {
        root: '/'
    }
</script>
    <!-- 不蒜子  -->
    
    <!-- CNZZ统计  -->
    
    </div>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>


